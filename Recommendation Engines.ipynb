{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Introduction\n",
    "## A. What is Recommendation Engine?\n",
    "## B. Evolution of Recommendation Engine\n",
    "## C. Examples of Uses of Recommendation Engine\n",
    "\n",
    "\n",
    "# II. Types of Recommendation Engines\n",
    "## A. Neighborhood-based Recommendation Engines\n",
    "### 1. Collaborative Filtering Systems\n",
    "#### a. User-based Collaborative Filtering\n",
    "#### b. Item-based Collaborative Filtering\n",
    "#### c. Memory-based Collaborative Filtering\n",
    "#### d. Model-based Collaborative Filtering\n",
    "### 2. Personalized Recommendation Engines\n",
    "#### a. Content-based Recommendation Engines\n",
    "#### b. Context-based Recommendation Engines\n",
    "## B. Hybrid Recommendation Engines\n",
    "### 1. Weighted Method\n",
    "### 2. Mixed Method\n",
    "### 3. Cascade Method\n",
    "### 4. Feature Combination Method\n",
    "## C. Machine Learning\n",
    "### 1. Dimensionary Reduction\n",
    "#### a. SVD - Snigle Value Decomposition\n",
    "#### b. PCA - Principle Component Analysis (Burayı genişleyecek)\n",
    "#### c. LDA - Linear Discriminant Analysis\n",
    "### 2. Clustering and Classification Algorithms\n",
    "#### a. K-NN - K-Nearest Neighborhood\n",
    "#### b. K-Means\n",
    "### 3. Regression Methods\n",
    "#### a. Linear Regression\n",
    "\n",
    "# III. Building Recommendation Engine\n",
    "## A.Exploring the Jester5k Dataset\n",
    "### 1. Details About Dataset\n",
    "### 2. Exploring the Dataset\n",
    "## B. Building User-based Collaborative Filtering With Recommenderlab\n",
    "### 1. Preparing Training and Test Data\n",
    "### 2. Creating a User-based Collaborative Model\n",
    "### 3. Predictions on the Test Set\n",
    "### 4. Analyzing the Dataset\n",
    "### 5. Creating the Recommendation Model With the k-Fold Cross-Validation\n",
    "### 6. Designing User-Based Collaborative Filtering\n",
    "## C. Building an Item-based Recommender Model\n",
    "### 1. Preparing Training and Test Data\n",
    "### 2. Creating a Item-based Collaborative Model\n",
    "### 3. Evaluating the Model\n",
    "### 4. Accuracy of the Model\n",
    "### 5. Model Accuracy With Plots\n",
    "### 6. Setting Parameter for Item-based Collaborative Filtering\n",
    "\n",
    "# IV. Analysis of Results\n",
    "\n",
    "# V. Refences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Introduction\n",
    "## A. What is Recommendation Engine?\n",
    "    \n",
    "In real life one decides to buy an item based on their own taste, suggestions from their friends and family and their own experience, but nowadays the digital world has grown into something that goes beyond asking around to buy something, simply because everything is now faster and more achievable over the digital world, and the buying experience (this can be anything, from buying plane tickets to a vacation, buying a shower gel to hiring a tutoring service etc.) slowly changing, evolving into a more digitized and personal experience rather than a social one.\n",
    "\n",
    "In this digital age the recommendation systems seem to have gained an important place for themselves. In fact, they are the ones to create the real-time, personalized, current and present experience for the users. Recommendation systems use huge chunks of data to analyze to give the most accurate suggestions for the users. They merely facilitate the choosing process, by narrowing down the options for the user, in which they are predicted to be interested.\n",
    "\n",
    "In mathematical terms;\n",
    "\n",
    "If $U$ denotes users, $I$ denotes items then $F$ denotes utility function and computes the usefulness of item $I$ to user $U$, given by:\n",
    "\n",
    "$$ F: U \\times I \\to [0, \\infty)  $$\n",
    "\n",
    "For each user $u$, we want to choose the item $i$ that maximizes the objective function: for a fixed user $u \\in U$,\n",
    "\n",
    "$$ R(u) = argmax_{i \\in I} F(u,i)$$\n",
    "\n",
    "Where $R$ denotes recommended items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Evolution of Recommendation Engine\n",
    "\n",
    "Digital recommendation systems might seem like a new concept, but we can say that there is prior art. We can talk about suggestion and recommendation where there is sharing. This is also true for the animals. Ants for example use a recommendation system in order to tell the rest of the clan. A pioneer ant leaves a mark which can be considered as a recommending system, in which the others know where to find food. This applies differently in humans, because we have language to communicate and taste to determine the preferences. There are people around us that we trust with suggestions, because we feel like they know us, and others not so much. Because we think that they do not fully understand us or our preferences. So when we need to decide on something to buy, we consult the ones we trust. We think that they are going to direct us in a way that coincides with our preferences, whether because they have made suggestions before and we were satisfied or simply because they understand us. It will not be wrong to assume that the recommendation engines of today takes the human nature as basis to make suggestions. \n",
    "\n",
    "Recommender engines evolved in the mid 1970's in Duke University as an independent research area. Since then, a lot of approaches were developed. The first recommender system to be used was Tapestry<sup>1</sup> , which was developed at the Xerox  Palo  Alto  Research Centre. The motivation behind this, was to sort out the unnecessary and irrelevant e-mails from the relevant ones. To overcome this problem, a mailing list was defined for each user, and if an incoming e-mail was out of this list, it would fall into the spam box. After this, recommender engines started to be used by various, popular internet sites such as, Amazon, Netflix, Social & Professional Networking Sites, Travel sites etc. Recommendation engines incorporated Artificial Intelligence, Information retrieval and Human-computer  interaction along the way of its development, in order to create more accurate and precise suggestion systems.<sup>2</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Examples of Uses of Recommendation Engine\n",
    "\n",
    "#### LinkedIn\n",
    "LinkedIn is a social network site for professionals in which proposals are framed for individuals you may know, occupations you may like, business groupes you should pursue based on your interests, skills and experiences, or organizations you may be keen on. LinkedIn utilizes Apache Hadoop to fabricate its specific communitarian separating abilities.\n",
    "\n",
    "#### Amazon\n",
    "Amazon is one of the largest web-based retailers. It utilizes content-based recommendation; when you select to buy something, the site suggests different items based on different clients' obtained dependent on that one unique item (as a matrix of thing to-probability-of-next-thing to buy). So, basically, Amazon, recommends next-item-to-be-bought, based on other clients' content data which are similar to yours. Amazon called this recommendation and filtering system \"item-to-item collaborative filtering\".\n",
    "\n",
    "#### Netflix\n",
    "Netflix is streaming service, which allows its customers to stream movies, TV series, documentaries etc. based on and by comparing your data to other customers' interests. Netflix offers a large number of content, thus it becomes almost impossible to find something that appeals to you if there is no one to guide you, unless you are seeking a specific thing. This site uses hybrid recommender systems, which begins by looking at your search history and review tendency for clients with similar interests.\n",
    "\n",
    "#### Spotify\n",
    "Spotify is a Swedish sound streaming platform that gives DRM-shielded music and digital broadcasts. This platform blends the methodologies to come up with the most-likely-to-be-liked-by-the-listener playlist every week, which is the Discover Weekly Playlist. Spotify uses collaborative filtering in order to create the best version of a new playlist that the user may like. We are going to talk about collaborative filtering in the sections below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Types of Recommendation Engines\n",
    "\n",
    "## A. Neighborhood-based Recommendation Engines\n",
    "\"The idea for neighborhood-based recommenders is very simple: given the ratings of a user, find all the users similar to the active user who had similar preferences in the past and then make predictions regarding all unknown products that the active user has not rated but are being rated in their neighborhood.\"<sup>3</sup> The user called \"active\" is the one that is actively being recommended by the system. These types of recommendation engines are also called \"similarity-based recommender systems\"<sup>4</sup>, simply because the recommendations are made considering the similarities. Also, another nomenclature is applicable, \"collaborative filtering\", since the data is used collaboratively from a pool of users.\n",
    "\n",
    "\"<b>These heuristic-based methods are based on the following assumptions:</b>\n",
    "- People with similar preferences in the past have similar preferences in the future\n",
    "- People's preferences will remain stable and consistent in the future\n",
    "\n",
    "<b>The collaborative filtering systems come in two flavors:</b>\n",
    "- User-based collaborative filtering\n",
    "- Item-based collaborative filtering\" <sup>5</sup>\n",
    "\n",
    "These methods are used when we only can obtain the user's interaction data (e.g. ratings, like/unlike, etc.). The properties of the products of the personal interests of the users in them are not taken into account.\n",
    "\n",
    "### 1. Collaborative Filtering Systems\n",
    "#### a. User-based Collaborative Filtering\n",
    "As we have mentioned earlier, collaborative filtering assumes that people with similar preferences in the past will have similar preferences in the future. Therefore, if $X$ buys a certain item and $X$ and $Y$ have similar tastes, $Y$ would also be interested in buying the same item even though he hasn't seen it yet.\n",
    "\n",
    "To summarize in two steps:\n",
    "1. Calculating the similarities between users in the pool, considering their interaction with the item.\n",
    "2. Predicting the unknown interaction of the active user of this new product and suggesting it accordingly.\n",
    "\n",
    "#### b. Item-based Collaborative Filtering\n",
    "Unlike user-based collaborative filtering, item-based collaborative filtering takes into account only the items and that active user's interaction with that item. To explain further, if the active user purchased item $U$, and item $Z$ and $U$ are similar to one another, then it is likely that, the active user will be interested in the item $Z$.\n",
    "\n",
    "Similar to user-based collaborative filtering there are two steps:\n",
    "1. Calculating the similarities between items of active users.\n",
    "2. Predicting the unknown item's likelihood of serving the active user's taste, using the same user's ratings of other items already purchased.\n",
    "\n",
    "###### Comparison \n",
    "Basically, we can say that item-based collaborative filtering looks like a more promising method. Simply because in user-based collaborative filtering, the users' ratings have the disadvantage of changing the data pool and expanding it every time the similar users' experience changes. Thus creating a bigger data pool to be dealt with, whereas in item-based collaborative filtering the data pool that is computed to suggest a new item every time is the active user's own ratings which makes it cost-wise more efficient. On the other hand, it is important to consider that the item-based collaborative filtering method performs poorly when we have very little data (e.g. when dealt with a new user with no data - cold-start problem - or a new user with a very few data on hand), and it fails to suggest very accurate recommendations since it is only based on rating info.\n",
    "\n",
    "#### c. Memory-Based Collaborative Filtering \n",
    "\n",
    "The memory-based method utilizes user rating data to process the similarities between users or items. Representative examples of this method are neighborhood-based CF and item-based/user-based top-N suggestions. For instance, in user-based methods, the estimation of ratings user $u$ provides for item $i$ is determined as a collection of some comparable users' rating of the item:\n",
    "\n",
    "$$r_{u,i}=\\operatorname {aggr} _{u^{\\prime }\\in U}r_{u^{\\prime },i}$$ \n",
    "\n",
    "where $U$ signifies the arrangement of top $N$ users that are most like the user $u$ who rated item $i$. A few instances of the aggregation function incorporates:\n",
    "\n",
    "$$r_{u,i}={\\frac {1}{N}}\\sum \\limits _{u^{\\prime }\\in U}r_{u^{\\prime },i}$$ \n",
    "$$r_{u,i}=k\\sum \\limits _{u^{\\prime }\\in U}\\operatorname {simil} (u,u^{\\prime })r_{u^{\\prime },i}$$\n",
    "where k is a normalizing element defined as \n",
    "$$k=\\frac {1}{\\sum _{u^{\\prime }\\in U}|\\operatorname {simil} (u,u^{\\prime })|},$$ and\n",
    "\n",
    "$$r_{u,i}={\\bar {r_{u}}}+k\\sum \\limits _{u^{\\prime }\\in U}\\operatorname {simil} (u,u^{\\prime })(r_{u^{\\prime },i}-{\\bar {r_{u^{\\prime }}}})$$\n",
    "where ${\\bar {r_{u}}}$ is the average rating of user u for all the items rated by $u$.\n",
    "\n",
    "The neighborhood-based algorithm computes the similitude between two users or items and produces a prediction for the user by taking the weighted average of the sum of the ratings. Similarity computation between items or users is a significant component of this method. Various measures, for example, Pearson correlation and vector cosine-based similarity are utilized for this.\n",
    "\n",
    "The Pearson correlation similarity of two users $x, y$ is characterized as\n",
    "\n",
    "$\\operatorname {simil} (x,y)={\\frac {\\sum \\limits _{i\\in I_{xy}}(r_{x,i}-{\\bar {r_{x}}})(r_{y,i}-{\\bar {r_{y}}})}{{\\sqrt {\\sum \\limits _{i\\in I_{xy}}(r_{x,i}-{\\bar {r_{x}}})^{2}}}{\\sqrt {\\sum \\limits _{i\\in I_{xy}}(r_{y,i}-{\\bar {r_{y}}})^{2}}}}}$ <br>\n",
    "where I<sub>xy</sub> is the set of items rated by both user $x$ and user $y$.\n",
    "\n",
    "The cosine-based approach defines the cosine-similarity between two users $x$ and $y$ as:\n",
    "\n",
    "$$\\operatorname {simil} (x,y)=\\cos({\\vec {x}},{\\vec {y}})={\\frac {{\\vec {x}}\\cdot {\\vec {y}}}{||{\\vec {x}}||\\times ||{\\vec {y}}||}}={\\frac {\\sum \\limits _{i\\in I_{xy}}r_{x,i}r_{y,i}}{{\\sqrt {\\sum \\limits _{i\\in I_{x}}r_{x,i}^{2}}}{\\sqrt {\\sum \\limits _{i\\in I_{y}}r_{y,i}^{2}}}}}$$\n",
    "\n",
    "The user-based top-N recommendation algorithm utilizes a similarity based vector model to distinguish the k most similar users to an active user. After the k most similar users are discovered, their relating user-item matrices are combined to distinguish the set of items to be suggested. A preferred method to locate similar users is the locality-sensitive hashing, which executes the closest neighbor system in linear time. \n",
    "\n",
    "The advantaged of this method contains the reasonableness of the outcomes, which is a significant part of recommendation systems; simple creation and use; simple facilitation of new data; content-autonomy of the items being suggested; good scaling with co-rated items.\n",
    "\n",
    "There are additionally a few drawbacks with this method. Its performance reduces when data is limited, which happens regularly with web-related items. This ruins the versatility of this method and creates issues with very big data-sets. In spite of the fact that it can effectively deal with new users since it depends on a data structure, including new items becomes more complex since that portrayal more often than not depends on a particular vector space. Including new items requires incorporation of the new item and the re-addition of the total number of components in the structure.\n",
    "\n",
    "#### d. Model-Based Collaborative Filtering \n",
    "\n",
    "In this method, models are created utilizing various data mining, machine learning algorithms to foresee users' rating of unrated items. There are many model-based CF algorithms. Bayesian networks, clustering models, latent semantic models, for example, singular value decomposition, probabilistic latent semantic analysis, multiple multiplicative factors, latent Dirichlet allocation, and Markov decision process based models.\n",
    "\n",
    "Through this method, dimensionality reduction methods are generally being used as a corresponding technique to improve the validity and exactness of the memory-based method. In this sense, methods like singular value decomposition, guideline element analysis, known as latent factor models, pack user-item matrix into a low-dimensional portrayal as far as latent elements. One vantage point of utilizing this method is that as opposed to having a high dimensional matrix containing a large number of missing values we will manage a lot smaller matrix in lower-dimensional space. A diminished introduction could be used for either user-based or item-based neighborhood algorithms that are previously mentioned. There are a few points of interest in this paradigm. It handles the sparsity compared to memory-based methods. Additionally, the resulting matrix is significantly more adaptable, particularly in managing big limited data sets.\n",
    "\n",
    "### 2. Personalized Recommendation Engines\n",
    "We can say that personalized recommendation engines function better in delivering more personalized recommendations because they take more factors into consideration. We can categorize content-based recommendation engines and context-based recommendation engines under personalized recommendation engines.\n",
    "\n",
    "#### a. Content-based recommendation engines\n",
    "A recommendation that aims to create more individualized suggestions and thus producing a more personalized experience to users through the active users' individual taste and preferences, based on the content of the products, is called a content-based recommendation engine. In spite of being a more individualized recommendation method, a content-based recommendation engine solves the cold-start problem that collaborative filtering systems come across. By initially demanding the user's preferences, this problem seems to dissolve.\n",
    "\n",
    "\"Three steps of content-based recommendation engines:\n",
    "1. Generating content information for products.\n",
    "2. Generating a user profile and preferences with respect to the features of the products.\n",
    "3. Generating recommendations and predicting a list of items that the user might like.\" <sup></sup>\n",
    "\n",
    "Simply put, a content-based recommendation engine considers both product content and the user profile to generate a more individualized recommendation, creating a more personalized experience. \n",
    "\n",
    "<b>Item profile generation:</b>\n",
    "In this step, the products are examined by their features. The products and their features are represented in a vector space model, this means the content of the product is portrayed. By doing so, the relative importance of the products’ features is laid out.\n",
    "\n",
    "<b>User profile generation:</b>\n",
    "This step calls for a matrix that matches the products’ content and with user profiles. User profile generation is crucial for content-based recommendation engines because by doing so, the data obtain more meaning by cross-referencing the item and user profiles. Thus, the similarities between them come out, revealing a meaningful recommendation path.\n",
    "\n",
    "#### b. Context-aware recommendation engines\n",
    "Context simply gives us the advantage to understand the state of the user. Understanding the context that the users are in, such as place, weather, time, season, state of mind, device, location of home or office, life events, etc., help us apprehend the context information and recommend a customized and more personalized item.\n",
    "\n",
    "To better understand we can give the following examples; if an e-retail website can know that a user is going on a gala of some sort, it can recommend a nightgown or a tux, or if an airline e-retailer understands the user’s wish to visit another country or city, it can recommend plane ticket campaigns accordingly.\n",
    "\n",
    "Context-aware recommendation engines give us the opportunity to look at a two-dimensional problem, which only contained the preference and the item, in three-dimensions, adding the context as the third dimension. This helps narrow down the recommendation options.\n",
    "\n",
    "The two steps of the context-based recommendation engine:\n",
    "1.    Generate content-based recommendations.\n",
    "2.    Take the content-based recommendations and add the third dimension, context, and filter the recommendations by it.\n",
    "\n",
    "There are two options as to when to use the context information.\n",
    "1.    Pre-filtering approach\n",
    "2.    Post-filtering approach\n",
    "\n",
    "<b>Pre-filtering approach</b>\n",
    "In this approach, the context information is used to filter out a context relevant item and preference content, so the final personalized recommendations are generated by using the three dimensions. The context information is added to the equation **before** generating personalized recommendations from the item content and user preference based information, therefore it is called the pre-filtering approach.\n",
    "\n",
    "<b>Post-filtering approach</b>\n",
    "This approach applies the context information **after** forming a personalized data through item content and user preferences are used to generate a list by the content-based recommendation engine. Here, the context information is applied to rule out the irrelevant recommendations generated through the content-based recommendation engine.\n",
    "\n",
    "###### Comparison \n",
    "Context-based recommendation engines incorporate content-based recommendations adding the context element helping even more specific suggestions to be made. Although content-based recommendation engines lack the context dimension, it has a surprise element in which the context-based recommendation engines do not deliver. In being too precise, the context-based recommendations show the items that the user will most probably buy even without a recommendation system, but it misses out on the chance to show a different item to the user, to direct them on a different path.\n",
    "\n",
    "These systems, both content and context-based, rather than using a pool of users to generate suggestions, they generate them according to the user’s preference and this user’s only, taking it to a more personalized level, as mentioned before. This increases the likelihood of the recommended item to be purchased, compared to the collaborative approaches. But by doing this, the users are only shown the items that are similar to their taste, content-wise, this means that they are going to miss out on the trending items. Also, these systems seem to have surpassed the cold-start problem.\n",
    "\n",
    "Even though both content and context-based recommendation systems have a real-time feel, context-based offers a more real service in its nature, by taking it further ahead by understanding the setting and the behavior of the user, staying more present than the content-based recommendation systems.\n",
    "\n",
    "## B. Hybrid Recommendation Engines\n",
    "Collaborative filtering and content-based recommendation systems have proven to be effective and serve needs in broad scope, but they each have their own limitations. This promoted a new way of using them, in combinations. This type of combined usage is called hybrid recommendation engines. Using these types of combined methods, we get more improved accuracy.\n",
    "\n",
    "### 1. Weighted method \n",
    "Toward the start of the arrangement of this weighted hybrid recommendation engine, equivalent loads will be given to each of the outcomes from accessible recommendation engines, and step by step the loads will be adjusted by assessing the reactions from the users to recommendations.\n",
    "### 2. Mixed Method\n",
    "This system is generally utilized in spots where it is not attainable to accomplish a score for an item by all the accessible recommender systems in view of data sparsity. So, recommendations are generated independently and are combined before something is suggested to the user.\n",
    "### 3. Cascade Method\n",
    "In this method, suggestions are produced using collaborative filtering, after that the content-based recommendation method is applied. Later on the last proposals are given to the user.\n",
    "### 4. Feature Combination Method\n",
    "In this method, both User-Item preferences drawn out from the content-based recommendation system and user-item ratings information is used to create a new hybrid recommendation engine.\n",
    "\n",
    "## C. Machine Learning\n",
    "### 1. Dimensionary Reduction\n",
    "#### a. SVD (Singular Value Decomposition)\n",
    "If $A$ is an $m\\times n$ real matrix with $m>n$, then $A$ can be written using a alleged singular value decomposition of the form\n",
    "\n",
    "$$A=UDV^T.$$    \n",
    " \n",
    "Notice that, there are several conflicting notational conventions in use in the literature. Press *et al.* (1992) define $U$ to be an $m \\times n$ matrix, $D$ as $n\\times n$, and $V$ as $n \\times n$<sup>7</sup>. In this system, $U$ and $V$ have orthogonal columns so that;\n",
    "\n",
    "$$U^TU=I$$\n",
    "\n",
    "and\n",
    "\n",
    "$$V^TV=I$$\n",
    "\n",
    "(where the two identity matrices may have different dimensions), and $D$ has entries only along the diagonal. For a complex matrix $A$, the singular value decomposition is a decomposition into the form\n",
    "\n",
    "$$A=UDV^H$$,     \n",
    "\n",
    "where $U$ and $V$ are unitary matrices, $V^H$ is the conjugate transpose of $V$, and $D$ is a diagonal matrix whose components are the singular values of the original matrix. If $A$ is a complex matrix, then there always exists such a decomposition with positive singular values<sup>8</sup>.\n",
    "\n",
    "#### b. PCA - Principle Component Analysis \n",
    "PCA is a dimensionality-rebate method that is generally used to diminish the dimensionality of huge data sets, by transforming a large collection of variables into a smaller one that still involves most of the knowledge in the huge set. PCA algorithm works like below;\n",
    "1. The analysis begin with the covariance matrix. All covariance of all the original variables needs to be calculated. Then the covariance matrix will be made\n",
    "2. For this covariance matrix, we will compute the eigenvectors and eigenvalues\n",
    "3. Each eigenvector would be a column vector with the same number of components as the variables in the first dataset. Hence that we had an initial dataset of the size $T \\times n$ (rows are the perceptions, columns stand for variables, $T$ is the observations), the covariance matrix would be of the size $n \\times n$, and each of the eigenvectors will be $n \\times 1$.\n",
    "4. The eigenvalues for each of the eigenvectors stand for the measure of variance that the given eigenvector represents. We set up the eigenvectors in descending order of the eigenvalues, and pick the best 2, 3 or the same number of eigenvalues that we are concerned how much variance we need to catch in our model. If we incorporate all the eigenvectors, at that point we would have caught all the variance yet this would not give us any favorable position over our initial data.\n",
    "\n",
    "#### c. LDA - Linear Discriminant Analysis \n",
    "LDA is also a dimensionality-rebate technique but it is a supervised method. LDA tries to accomplish to opposing goals at the same time: \n",
    "\n",
    "1. It tries to keep classes as compact as possible within themselves, \n",
    "2. It tries to separate class centroids as far as possible.\n",
    "\n",
    "LDA can be attained in three steps : \n",
    "1. Determining the divisibility between various classes. \n",
    "$$ S_b=\\sum_{i=1}^g N_i(\\overline x_i - \\overline x)(\\overline x_i - \\overline x)^T$$\n",
    "\n",
    "2. Determining the length between the mean and sampling of any collection, that is called the class variance \n",
    "$$S_w=\\sum_{i=1}^g (N_i - 1)S_i = \\sum_{i=1}^g \\sum_{j=1}^(N_i) (x_i,_j - \\overline x_i)(x_i,_j - \\overline x_i)^T$$ <br>\n",
    "\n",
    "\n",
    "3. Constructing the lower dimensional space which maximizes the between-class variance and minimizes the within-class variance. Let P be the lower dimensional space projection, which is called Fisher’s measure.<br>\n",
    "$$P_{lda}=arg_p max \\frac{\\vert{P^TS_bP}\\vert}{\\vert{P^TS_wP}\\vert}$$\n",
    "\n",
    "### 2. Clustering and Classification Algorithms\n",
    "#### a. K-NN  (K-Nearest Neighborhood)\n",
    "K nearest neighbors is a basic algorithm that stores every accessible case and arranges new cases based on a similarity measure (for example, distance functions). KNN has been used in statistical estimation and pattern recognition in the early 1970s as a non-parametric technique.\n",
    "\n",
    "Algorithm;\n",
    "\n",
    "A case is grouped by a majority vote of its neighbors, with the case being assigned to the class most common among its K nearest neighbors, calculated by a distance function. In the event that $K = 1$, at that point the case is basically assigned to the class of its nearest neighbor.\n",
    "\n",
    "It should likewise be noticed that every one of the three distance measures is only valid for continuous variables. In the occasion of categorical variables, the Hamming distance must be used. It likewise raises the issue of standardization of the numerical variables in the range of 0 and 1 when there is a blend of numerical and categorical variables in the data set.\n",
    "\n",
    "Picking the optimal value for K is best done by first reviewing the data. Generally, a big K value is more exact as it decreases the general commotion however there is no assurance. Cross-validation is another approach to reflectively decides a decent K value by using an independent data set to validate the K value. In the past, the optimal K for most data sets has been between 3-10. That produces many preferable outcomes over 1-NN.\n",
    "\n",
    "#### b. K-Means\n",
    "One of the most direct assignments we can perform on a data set without labels is to discover bunches of data in our data set which are like - what we call clusters. K-Means stands out amongst the most well known \"clustering\" algorithms. K-Means stores k centroids that it uses to characterize clusters. A point is viewed as in a specific cluster on the off chance that it is nearer to that group's centroid than some other centroid. K-Means finds the best centroids by shifting back and forth between relegating information focuses to clusters dependent on the present centroids and choosing centroids (focuses which are the focal point of a group) in light of the present task of data points to clusters.\n",
    "\n",
    "### 3. Regression Methods\n",
    "#### a. Linear Regression\n",
    "In statistics, linear regression is a linear way to display the connection between a scalar reaction (or dependent variable) and at least one informative factor (or autonomous factors). The instance of one explanatory variable is called simple linear regression. For more than one explanatory variable, the procedure is called multiple linear regression. This term is discrete from multivariate linear regression, where multiple correlated dependent variables are anticipated, instead of a single scalar variable. In linear regression, the connections are displayed utilizing linear predictor functions whose unknown model parameters are evaluated from the data. Such models are called linear models. Mostly, the conditional mean of the reaction given the estimations of the explanatory variables (or predictors) is thought to be a relative function of those values; less known for, the conditional mean or some other quantile is utilized. Like all types of regression analysis, linear regression centers around the circumstantial probability distribution of the reaction given the estimations of the predictors, as opposed to on the joint probability distribution of all of these factors, which is the area of multivariate analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Building Recommendation Engine\n",
    "## A. Exploring the Jester5k Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains a sample of 5000 users from the anonymous rating data from the Jester Online Joke Recommender System collected between April 1999 and May 2003/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# At the beginning we need to install the libraries that we will use, which is \"Recommenderlab\"\n",
    "if(!\"recommenderlab\" %in% rownames(installed.packages())){\n",
    "install.packages(\"recommenderlab\")}\n",
    "library(recommenderlab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 5 × 2 of type chr[,2]</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Item</th><th scope=col>Title</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Jester5k                   </td><td>Jester dataset (5k sample)               </td></tr>\n",
       "\t<tr><td>JesterJokes (Jester5k)     </td><td>Jester dataset (5k sample)               </td></tr>\n",
       "\t<tr><td>MSWeb                      </td><td>Anonymous web data from www.microsoft.com</td></tr>\n",
       "\t<tr><td>MovieLense                 </td><td>MovieLense Dataset (100k)                </td></tr>\n",
       "\t<tr><td>MovieLenseMeta (MovieLense)</td><td>MovieLense Dataset (100k)                </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 5 × 2 of type chr{[},2{]}\n",
       "\\begin{tabular}{ll}\n",
       " Item & Title\\\\\n",
       "\\hline\n",
       "\t Jester5k                    & Jester dataset (5k sample)               \\\\\n",
       "\t JesterJokes (Jester5k)      & Jester dataset (5k sample)               \\\\\n",
       "\t MSWeb                       & Anonymous web data from www.microsoft.com\\\\\n",
       "\t MovieLense                  & MovieLense Dataset (100k)                \\\\\n",
       "\t MovieLenseMeta (MovieLense) & MovieLense Dataset (100k)                \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 5 × 2 of type chr[,2]\n",
       "\n",
       "| Item | Title |\n",
       "|---|---|\n",
       "| Jester5k                    | Jester dataset (5k sample)                |\n",
       "| JesterJokes (Jester5k)      | Jester dataset (5k sample)                |\n",
       "| MSWeb                       | Anonymous web data from www.microsoft.com |\n",
       "| MovieLense                  | MovieLense Dataset (100k)                 |\n",
       "| MovieLenseMeta (MovieLense) | MovieLense Dataset (100k)                 |\n",
       "\n"
      ],
      "text/plain": [
       "     Item                        Title                                    \n",
       "[1,] Jester5k                    Jester dataset (5k sample)               \n",
       "[2,] JesterJokes (Jester5k)      Jester dataset (5k sample)               \n",
       "[3,] MSWeb                       Anonymous web data from www.microsoft.com\n",
       "[4,] MovieLense                  MovieLense Dataset (100k)                \n",
       "[5,] MovieLenseMeta (MovieLense) MovieLense Dataset (100k)                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# From this library we are going to take a dataset that we need. We will use Jester5k dataset.\n",
    "data_package <- data(package = \"recommenderlab\")\n",
    "data_package$results[,c(\"Item\",\"Title\")]\n",
    "data(Jester5k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Details About Dataset\n",
    "Jester5k contains a 5000 x 100 rating matrix (5000 users and 100 jokes) with ratings between -10.00 and +10.00. All selected users have rated 36 or more jokes. The data also contains the actual jokes in JesterJokes<sup>9</sup>\n",
    "\n",
    "The number of ratings present in the real-rating matrix is represented as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "362106"
      ],
      "text/latex": [
       "362106"
      ],
      "text/markdown": [
       "362106"
      ],
      "text/plain": [
       "[1] 362106"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'realRatingMatrix'"
      ],
      "text/latex": [
       "'realRatingMatrix'"
      ],
      "text/markdown": [
       "'realRatingMatrix'"
      ],
      "text/plain": [
       "[1] \"realRatingMatrix\"\n",
       "attr(,\"package\")\n",
       "[1] \"recommenderlab\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nratings(Jester5k)\n",
    "class(Jester5k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4674488 bytes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "object.size(Jester5k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4326888 bytes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If we convert the real-rating matrix into R matrix\n",
    "object.size(as(Jester5k,\"matrix\"))\n",
    "# the size will be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9 bytes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "object.size(as(Jester5k, \"matrix\"))/object.size(Jester5k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the real-rating matrix stores 7,5% less space than the R grid. For collaborative filtering methods, which are memory-based models, where every one of the information is stacked into the memory while producing suggestions, putting away information productively is significant. The recommenderlab bundle carries out this responsibility proficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accompanying code work applies the capacity to every one of the components of the rundown, for our situation, for every one of the things in the recommender_models object, lapply will extricate the portrayal and show the outcomes as pursues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " [1] [                      [<-                    binarize              \n",
       " [4] calcPredictionAccuracy coerce                 colCounts             \n",
       " [7] colMeans               colSds                 colSums               \n",
       "[10] denormalize            dim                    dimnames              \n",
       "[13] dimnames<-             dissimilarity          evaluationScheme      \n",
       "[16] getData.frame          getList                getNormalize          \n",
       "[19] getRatingMatrix        getRatings             getTopNLists          \n",
       "[22] image                  normalize              nratings              \n",
       "[25] Recommender            removeKnownRatings     rowCounts             \n",
       "[28] rowMeans               rowSds                 rowSums               \n",
       "[31] sample                 show                   similarity            \n",
       "see '?methods' for accessing help and source code"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "methods(class = class(Jester5k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will show us the available recommendation algorithms that we can use in the \"recommenderlab\" package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'ALS_realRatingMatrix'</li>\n",
       "\t<li>'ALS_implicit_realRatingMatrix'</li>\n",
       "\t<li>'IBCF_realRatingMatrix'</li>\n",
       "\t<li>'POPULAR_realRatingMatrix'</li>\n",
       "\t<li>'RANDOM_realRatingMatrix'</li>\n",
       "\t<li>'RERECOMMEND_realRatingMatrix'</li>\n",
       "\t<li>'SVD_realRatingMatrix'</li>\n",
       "\t<li>'SVDF_realRatingMatrix'</li>\n",
       "\t<li>'UBCF_realRatingMatrix'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'ALS\\_realRatingMatrix'\n",
       "\\item 'ALS\\_implicit\\_realRatingMatrix'\n",
       "\\item 'IBCF\\_realRatingMatrix'\n",
       "\\item 'POPULAR\\_realRatingMatrix'\n",
       "\\item 'RANDOM\\_realRatingMatrix'\n",
       "\\item 'RERECOMMEND\\_realRatingMatrix'\n",
       "\\item 'SVD\\_realRatingMatrix'\n",
       "\\item 'SVDF\\_realRatingMatrix'\n",
       "\\item 'UBCF\\_realRatingMatrix'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'ALS_realRatingMatrix'\n",
       "2. 'ALS_implicit_realRatingMatrix'\n",
       "3. 'IBCF_realRatingMatrix'\n",
       "4. 'POPULAR_realRatingMatrix'\n",
       "5. 'RANDOM_realRatingMatrix'\n",
       "6. 'RERECOMMEND_realRatingMatrix'\n",
       "7. 'SVD_realRatingMatrix'\n",
       "8. 'SVDF_realRatingMatrix'\n",
       "9. 'UBCF_realRatingMatrix'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"ALS_realRatingMatrix\"          \"ALS_implicit_realRatingMatrix\"\n",
       "[3] \"IBCF_realRatingMatrix\"         \"POPULAR_realRatingMatrix\"     \n",
       "[5] \"RANDOM_realRatingMatrix\"       \"RERECOMMEND_realRatingMatrix\" \n",
       "[7] \"SVD_realRatingMatrix\"          \"SVDF_realRatingMatrix\"        \n",
       "[9] \"UBCF_realRatingMatrix\"        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names(recommender_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code block shows a similar outcome as in the past outcome, lapply() function applies the capacity to every one of the components of the rundown, for our situation, for every one of the things in the recommender_models object, lapply will separate the depiction and show the outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$ALS_realRatingMatrix</dt>\n",
       "\t\t<dd>'Recommender for explicit ratings based on latent factors, calculated by alternating least squares algorithm.'</dd>\n",
       "\t<dt>$ALS_implicit_realRatingMatrix</dt>\n",
       "\t\t<dd>'Recommender for implicit data based on latent factors, calculated by alternating least squares algorithm.'</dd>\n",
       "\t<dt>$IBCF_realRatingMatrix</dt>\n",
       "\t\t<dd>'Recommender based on item-based collaborative filtering.'</dd>\n",
       "\t<dt>$POPULAR_realRatingMatrix</dt>\n",
       "\t\t<dd>'Recommender based on item popularity.'</dd>\n",
       "\t<dt>$RANDOM_realRatingMatrix</dt>\n",
       "\t\t<dd>'Produce random recommendations (real ratings).'</dd>\n",
       "\t<dt>$RERECOMMEND_realRatingMatrix</dt>\n",
       "\t\t<dd>'Re-recommends highly rated items (real ratings).'</dd>\n",
       "\t<dt>$SVD_realRatingMatrix</dt>\n",
       "\t\t<dd>'Recommender based on SVD approximation with column-mean imputation.'</dd>\n",
       "\t<dt>$SVDF_realRatingMatrix</dt>\n",
       "\t\t<dd>'Recommender based on Funk SVD with gradient descend.'</dd>\n",
       "\t<dt>$UBCF_realRatingMatrix</dt>\n",
       "\t\t<dd>'Recommender based on user-based collaborative filtering.'</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$ALS\\_realRatingMatrix] 'Recommender for explicit ratings based on latent factors, calculated by alternating least squares algorithm.'\n",
       "\\item[\\$ALS\\_implicit\\_realRatingMatrix] 'Recommender for implicit data based on latent factors, calculated by alternating least squares algorithm.'\n",
       "\\item[\\$IBCF\\_realRatingMatrix] 'Recommender based on item-based collaborative filtering.'\n",
       "\\item[\\$POPULAR\\_realRatingMatrix] 'Recommender based on item popularity.'\n",
       "\\item[\\$RANDOM\\_realRatingMatrix] 'Produce random recommendations (real ratings).'\n",
       "\\item[\\$RERECOMMEND\\_realRatingMatrix] 'Re-recommends highly rated items (real ratings).'\n",
       "\\item[\\$SVD\\_realRatingMatrix] 'Recommender based on SVD approximation with column-mean imputation.'\n",
       "\\item[\\$SVDF\\_realRatingMatrix] 'Recommender based on Funk SVD with gradient descend.'\n",
       "\\item[\\$UBCF\\_realRatingMatrix] 'Recommender based on user-based collaborative filtering.'\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$ALS_realRatingMatrix\n",
       ":   'Recommender for explicit ratings based on latent factors, calculated by alternating least squares algorithm.'\n",
       "$ALS_implicit_realRatingMatrix\n",
       ":   'Recommender for implicit data based on latent factors, calculated by alternating least squares algorithm.'\n",
       "$IBCF_realRatingMatrix\n",
       ":   'Recommender based on item-based collaborative filtering.'\n",
       "$POPULAR_realRatingMatrix\n",
       ":   'Recommender based on item popularity.'\n",
       "$RANDOM_realRatingMatrix\n",
       ":   'Produce random recommendations (real ratings).'\n",
       "$RERECOMMEND_realRatingMatrix\n",
       ":   'Re-recommends highly rated items (real ratings).'\n",
       "$SVD_realRatingMatrix\n",
       ":   'Recommender based on SVD approximation with column-mean imputation.'\n",
       "$SVDF_realRatingMatrix\n",
       ":   'Recommender based on Funk SVD with gradient descend.'\n",
       "$UBCF_realRatingMatrix\n",
       ":   'Recommender based on user-based collaborative filtering.'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$ALS_realRatingMatrix\n",
       "[1] \"Recommender for explicit ratings based on latent factors, calculated by alternating least squares algorithm.\"\n",
       "\n",
       "$ALS_implicit_realRatingMatrix\n",
       "[1] \"Recommender for implicit data based on latent factors, calculated by alternating least squares algorithm.\"\n",
       "\n",
       "$IBCF_realRatingMatrix\n",
       "[1] \"Recommender based on item-based collaborative filtering.\"\n",
       "\n",
       "$POPULAR_realRatingMatrix\n",
       "[1] \"Recommender based on item popularity.\"\n",
       "\n",
       "$RANDOM_realRatingMatrix\n",
       "[1] \"Produce random recommendations (real ratings).\"\n",
       "\n",
       "$RERECOMMEND_realRatingMatrix\n",
       "[1] \"Re-recommends highly rated items (real ratings).\"\n",
       "\n",
       "$SVD_realRatingMatrix\n",
       "[1] \"Recommender based on SVD approximation with column-mean imputation.\"\n",
       "\n",
       "$SVDF_realRatingMatrix\n",
       "[1] \"Recommender based on Funk SVD with gradient descend.\"\n",
       "\n",
       "$UBCF_realRatingMatrix\n",
       "[1] \"Recommender based on user-based collaborative filtering.\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lapply(recommender_models, \"[[\", \"description\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>5000</li>\n",
       "\t<li>100</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 5000\n",
       "\\item 100\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 5000\n",
       "2. 100\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 5000  100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can start exploring the data with finding its dimensions\n",
    "dim(Jester5k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'dgCMatrix'"
      ],
      "text/latex": [
       "'dgCMatrix'"
      ],
      "text/markdown": [
       "'dgCMatrix'"
      ],
      "text/plain": [
       "[1] \"dgCMatrix\"\n",
       "attr(,\"package\")\n",
       "[1] \"Matrix\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class(Jester5k@data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code line will enable us to comprehend the rating esteems distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nQmCC",
      "text/plain": [
       "Plot with title \"Distribution of Ratings\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist(getRatings(Jester5k), main=\"Distribution of Ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The former picture demonstrates the recurrence of the evaluations accessible from the Jester5K dataset. We can see that the negative evaluations are pretty much of uniform dissemination or the equivalent recurrence, and the positive evaluations are of a higher recurrence and are declining towards the right of the plot. This may credit to the inclination instigated by the appraisals given by the clients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Building User-based Collaborative Filtering With Recommenderlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 6 × 10 of type dbl[,10]</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>j1</th><th scope=col>j2</th><th scope=col>j3</th><th scope=col>j4</th><th scope=col>j5</th><th scope=col>j6</th><th scope=col>j7</th><th scope=col>j8</th><th scope=col>j9</th><th scope=col>j10</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>u2841</th><td> 7.91</td><td> 9.17</td><td> 5.34</td><td> 8.16</td><td>-8.74</td><td> 7.14</td><td> 8.88</td><td>-8.25</td><td> 5.87</td><td> 6.21</td></tr>\n",
       "\t<tr><th scope=row>u15547</th><td>-3.20</td><td>-3.50</td><td>-9.56</td><td>-8.74</td><td>-6.36</td><td>-3.30</td><td> 0.78</td><td> 2.18</td><td>-8.40</td><td>-8.79</td></tr>\n",
       "\t<tr><th scope=row>u15221</th><td>-1.70</td><td> 1.21</td><td> 1.55</td><td> 2.77</td><td> 5.58</td><td> 3.06</td><td> 2.72</td><td>-4.66</td><td> 4.51</td><td>-3.06</td></tr>\n",
       "\t<tr><th scope=row>u15573</th><td>-7.38</td><td>-8.93</td><td>-3.88</td><td>-7.23</td><td>-4.90</td><td> 4.13</td><td> 2.57</td><td> 3.83</td><td> 4.37</td><td> 3.16</td></tr>\n",
       "\t<tr><th scope=row>u21505</th><td> 0.10</td><td> 4.17</td><td> 4.90</td><td> 1.55</td><td> 5.53</td><td> 1.50</td><td>-3.79</td><td> 1.94</td><td> 3.59</td><td> 4.81</td></tr>\n",
       "\t<tr><th scope=row>u15994</th><td> 0.83</td><td>-4.90</td><td> 0.68</td><td>-7.18</td><td> 0.34</td><td>-4.32</td><td>-6.17</td><td> 6.12</td><td>-5.58</td><td> 5.44</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 6 × 10 of type dbl{[},10{]}\n",
       "\\begin{tabular}{r|llllllllll}\n",
       "  & j1 & j2 & j3 & j4 & j5 & j6 & j7 & j8 & j9 & j10\\\\\n",
       "\\hline\n",
       "\tu2841 &  7.91 &  9.17 &  5.34 &  8.16 & -8.74 &  7.14 &  8.88 & -8.25 &  5.87 &  6.21\\\\\n",
       "\tu15547 & -3.20 & -3.50 & -9.56 & -8.74 & -6.36 & -3.30 &  0.78 &  2.18 & -8.40 & -8.79\\\\\n",
       "\tu15221 & -1.70 &  1.21 &  1.55 &  2.77 &  5.58 &  3.06 &  2.72 & -4.66 &  4.51 & -3.06\\\\\n",
       "\tu15573 & -7.38 & -8.93 & -3.88 & -7.23 & -4.90 &  4.13 &  2.57 &  3.83 &  4.37 &  3.16\\\\\n",
       "\tu21505 &  0.10 &  4.17 &  4.90 &  1.55 &  5.53 &  1.50 & -3.79 &  1.94 &  3.59 &  4.81\\\\\n",
       "\tu15994 &  0.83 & -4.90 &  0.68 & -7.18 &  0.34 & -4.32 & -6.17 &  6.12 & -5.58 &  5.44\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 6 × 10 of type dbl[,10]\n",
       "\n",
       "| <!--/--> | j1 | j2 | j3 | j4 | j5 | j6 | j7 | j8 | j9 | j10 |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| u2841 |  7.91 |  9.17 |  5.34 |  8.16 | -8.74 |  7.14 |  8.88 | -8.25 |  5.87 |  6.21 |\n",
       "| u15547 | -3.20 | -3.50 | -9.56 | -8.74 | -6.36 | -3.30 |  0.78 |  2.18 | -8.40 | -8.79 |\n",
       "| u15221 | -1.70 |  1.21 |  1.55 |  2.77 |  5.58 |  3.06 |  2.72 | -4.66 |  4.51 | -3.06 |\n",
       "| u15573 | -7.38 | -8.93 | -3.88 | -7.23 | -4.90 |  4.13 |  2.57 |  3.83 |  4.37 |  3.16 |\n",
       "| u21505 |  0.10 |  4.17 |  4.90 |  1.55 |  5.53 |  1.50 | -3.79 |  1.94 |  3.59 |  4.81 |\n",
       "| u15994 |  0.83 | -4.90 |  0.68 | -7.18 |  0.34 | -4.32 | -6.17 |  6.12 | -5.58 |  5.44 |\n",
       "\n"
      ],
      "text/plain": [
       "       j1    j2    j3    j4    j5    j6    j7    j8    j9    j10  \n",
       "u2841   7.91  9.17  5.34  8.16 -8.74  7.14  8.88 -8.25  5.87  6.21\n",
       "u15547 -3.20 -3.50 -9.56 -8.74 -6.36 -3.30  0.78  2.18 -8.40 -8.79\n",
       "u15221 -1.70  1.21  1.55  2.77  5.58  3.06  2.72 -4.66  4.51 -3.06\n",
       "u15573 -7.38 -8.93 -3.88 -7.23 -4.90  4.13  2.57  3.83  4.37  3.16\n",
       "u21505  0.10  4.17  4.90  1.55  5.53  1.50 -3.79  1.94  3.59  4.81\n",
       "u15994  0.83 -4.90  0.68 -7.18  0.34 -4.32 -6.17  6.12 -5.58  5.44"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### At this point we will start to apply user-based Collaborative Filtering Recommenderlab \n",
    "library(recommenderlab)\n",
    "data(Jester5k)\n",
    "head(as(Jester5k,\"matrix\")[,1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparing Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>FALSE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>FALSE</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item FALSE\n",
       "\\item TRUE\n",
       "\\item FALSE\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. TRUE\n",
       "2. TRUE\n",
       "3. TRUE\n",
       "4. FALSE\n",
       "5. TRUE\n",
       "6. FALSE\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  TRUE  TRUE  TRUE FALSE  TRUE FALSE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### We need to arrange training and test data \n",
    "set.seed(1)\n",
    "# We will split the data 80% for train set and 20% for test set\n",
    "train_set <- sample(x = c(TRUE, FALSE), size = nrow(Jester5k),replace = TRUE, prob = c(0.8, 0.2)) \n",
    "# This line above will give us the training set which has logical values\n",
    "head(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nest step will be dividing the set such as train set and test set\n",
    "rec_data_train <- Jester5k[train_set, ] # Train set\n",
    "rec_data_test <- Jester5k[!train_set, ] # Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>3951</li>\n",
       "\t<li>100</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 3951\n",
       "\\item 100\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 3951\n",
       "2. 100\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 3951  100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dimension of the train set\n",
    "dim(rec_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1049</li>\n",
       "\t<li>100</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1049\n",
       "\\item 100\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1049\n",
       "2. 100\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1049  100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dimension of the test set\n",
    "dim(rec_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Creating a User-based Collaborative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$ALS_realRatingMatrix\n",
       "Recommender method: ALS for realRatingMatrix\n",
       "Description: Recommender for explicit ratings based on latent factors, calculated by alternating least squares algorithm.\n",
       "Reference: Yunhong Zhou, Dennis Wilkinson, Robert Schreiber, Rong Pan (2008). Large-Scale Parallel Collaborative Filtering for the Netflix Prize, 4th Int'l Conf. Algorithmic Aspects in Information and Management, LNCS 5034.\n",
       "Parameters:\n",
       "  normalize lambda n_factors n_iterations min_item_nr seed\n",
       "1      NULL    0.1        10           10           1 NULL\n",
       "\n",
       "$ALS_implicit_realRatingMatrix\n",
       "Recommender method: ALS_implicit for realRatingMatrix\n",
       "Description: Recommender for implicit data based on latent factors, calculated by alternating least squares algorithm.\n",
       "Reference: Yifan Hu, Yehuda Koren, Chris Volinsky (2008). Collaborative Filtering for Implicit Feedback Datasets, ICDM '08 Proceedings of the 2008 Eighth IEEE International Conference on Data Mining, pages 263-272.\n",
       "Parameters:\n",
       "  lambda alpha n_factors n_iterations min_item_nr seed\n",
       "1    0.1    10        10           10           1 NULL\n",
       "\n",
       "$IBCF_realRatingMatrix\n",
       "Recommender method: IBCF for realRatingMatrix\n",
       "Description: Recommender based on item-based collaborative filtering.\n",
       "Reference: NA\n",
       "Parameters:\n",
       "   k   method normalize normalize_sim_matrix alpha na_as_zero\n",
       "1 30 \"Cosine\"  \"center\"                FALSE   0.5      FALSE\n",
       "\n",
       "$POPULAR_realRatingMatrix\n",
       "Recommender method: POPULAR for realRatingMatrix\n",
       "Description: Recommender based on item popularity.\n",
       "Reference: NA\n",
       "Parameters:\n",
       "  normalize\n",
       "1  \"center\"\n",
       "                                                     aggregationRatings\n",
       "1 new(\"standardGeneric\", .Data = function (x, na.rm = FALSE, dims = 1, \n",
       "                                                  aggregationPopularity\n",
       "1 new(\"standardGeneric\", .Data = function (x, na.rm = FALSE, dims = 1, \n",
       "\n",
       "$RANDOM_realRatingMatrix\n",
       "Recommender method: RANDOM for realRatingMatrix\n",
       "Description: Produce random recommendations (real ratings).\n",
       "Reference: NA\n",
       "Parameters: None\n",
       "\n",
       "$RERECOMMEND_realRatingMatrix\n",
       "Recommender method: RERECOMMEND for realRatingMatrix\n",
       "Description: Re-recommends highly rated items (real ratings).\n",
       "Reference: NA\n",
       "Parameters:\n",
       "  randomize minRating\n",
       "1         1        NA\n",
       "\n",
       "$SVD_realRatingMatrix\n",
       "Recommender method: SVD for realRatingMatrix\n",
       "Description: Recommender based on SVD approximation with column-mean imputation.\n",
       "Reference: NA\n",
       "Parameters:\n",
       "   k maxiter normalize\n",
       "1 10     100  \"center\"\n",
       "\n",
       "$SVDF_realRatingMatrix\n",
       "Recommender method: SVDF for realRatingMatrix\n",
       "Description: Recommender based on Funk SVD with gradient descend.\n",
       "Reference: NA\n",
       "Parameters:\n",
       "   k gamma lambda min_epochs max_epochs min_improvement normalize verbose\n",
       "1 10 0.015  0.001         50        200           1e-06  \"center\"   FALSE\n",
       "\n",
       "$UBCF_realRatingMatrix\n",
       "Recommender method: UBCF for realRatingMatrix\n",
       "Description: Recommender based on user-based collaborative filtering.\n",
       "Reference: NA\n",
       "Parameters:\n",
       "    method nn sample normalize\n",
       "1 \"cosine\" 25  FALSE  \"center\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Since we made the train and test sets now we can start building a user-based collaborative model\n",
    "recommender_models <- recommenderRegistry$get_entries(dataType = \"realRatingMatrix\")\n",
    "recommender_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output shows the six distinct recommender models and their parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recommender of type 'UBCF' for 'realRatingMatrix' \n",
       "learned using 3951 users."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Since we are building  a user-basedd collaborative filtering model, we need to call that method first\n",
    "recc_model <- Recommender(data = rec_data_train, method = \"UBCF\")\n",
    "recc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3951 x 100 rating matrix of class 'realRatingMatrix' with 286396 ratings.\n",
       "Normalized using center on rows."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recc_model@model$data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Predictions on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recommendations as 'topNList' with n = 15 for 1049 users. "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### We create the model, now we are going to predict the recommendations for the test set. For prediction we will use the\n",
    "### predict() function which is stored in the library. We are going to develope 15 recommendations for each user.\n",
    "n_recommend <- 15\n",
    "recc_predicted <- predict(object = recc_model, newdata = rec_data_test, n = n_recommend)\n",
    "recc_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's assign the list of predicted recommendations\n",
    "rec_list <- sapply(recc_predicted@items, function(x){\n",
    "    colnames(Jester5k)[x]}\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'list'"
      ],
      "text/latex": [
       "'list'"
      ],
      "text/markdown": [
       "'list'"
      ],
      "text/plain": [
       "[1] \"list\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class(rec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$u7904</dt>\n",
       "\t\t<dd><ol class=list-inline>\n",
       "\t<li>'j28'</li>\n",
       "\t<li>'j38'</li>\n",
       "\t<li>'j14'</li>\n",
       "\t<li>'j26'</li>\n",
       "\t<li>'j22'</li>\n",
       "\t<li>'j3'</li>\n",
       "\t<li>'j34'</li>\n",
       "\t<li>'j10'</li>\n",
       "\t<li>'j100'</li>\n",
       "\t<li>'j89'</li>\n",
       "\t<li>'j80'</li>\n",
       "\t<li>'j52'</li>\n",
       "\t<li>'j70'</li>\n",
       "\t<li>'j77'</li>\n",
       "\t<li>'j51'</li>\n",
       "</ol>\n",
       "</dd>\n",
       "\t<dt>$u20747</dt>\n",
       "\t\t<dd><ol class=list-inline>\n",
       "\t<li>'j83'</li>\n",
       "\t<li>'j89'</li>\n",
       "\t<li>'j93'</li>\n",
       "\t<li>'j91'</li>\n",
       "\t<li>'j92'</li>\n",
       "\t<li>'j72'</li>\n",
       "\t<li>'j84'</li>\n",
       "\t<li>'j97'</li>\n",
       "\t<li>'j100'</li>\n",
       "\t<li>'j98'</li>\n",
       "\t<li>'j78'</li>\n",
       "\t<li>'j87'</li>\n",
       "\t<li>'j81'</li>\n",
       "\t<li>'j82'</li>\n",
       "\t<li>'j86'</li>\n",
       "</ol>\n",
       "</dd>\n",
       "\t<dt>$u4519</dt>\n",
       "\t\t<dd><ol class=list-inline>\n",
       "\t<li>'j89'</li>\n",
       "\t<li>'j88'</li>\n",
       "\t<li>'j87'</li>\n",
       "\t<li>'j72'</li>\n",
       "\t<li>'j91'</li>\n",
       "\t<li>'j92'</li>\n",
       "\t<li>'j84'</li>\n",
       "\t<li>'j80'</li>\n",
       "\t<li>'j83'</li>\n",
       "\t<li>'j81'</li>\n",
       "\t<li>'j71'</li>\n",
       "\t<li>'j73'</li>\n",
       "\t<li>'j79'</li>\n",
       "\t<li>'j75'</li>\n",
       "\t<li>'j78'</li>\n",
       "</ol>\n",
       "</dd>\n",
       "\t<dt>$u13802</dt>\n",
       "\t\t<dd><ol class=list-inline>\n",
       "\t<li>'j72'</li>\n",
       "\t<li>'j93'</li>\n",
       "\t<li>'j80'</li>\n",
       "\t<li>'j75'</li>\n",
       "\t<li>'j87'</li>\n",
       "\t<li>'j89'</li>\n",
       "\t<li>'j91'</li>\n",
       "\t<li>'j81'</li>\n",
       "\t<li>'j100'</li>\n",
       "\t<li>'j76'</li>\n",
       "\t<li>'j79'</li>\n",
       "\t<li>'j77'</li>\n",
       "\t<li>'j90'</li>\n",
       "\t<li>'j97'</li>\n",
       "\t<li>'j73'</li>\n",
       "</ol>\n",
       "</dd>\n",
       "\t<dt>$u7722</dt>\n",
       "\t\t<dd><ol class=list-inline>\n",
       "\t<li>'j87'</li>\n",
       "\t<li>'j83'</li>\n",
       "\t<li>'j86'</li>\n",
       "\t<li>'j3'</li>\n",
       "\t<li>'j89'</li>\n",
       "\t<li>'j76'</li>\n",
       "\t<li>'j72'</li>\n",
       "\t<li>'j78'</li>\n",
       "\t<li>'j92'</li>\n",
       "\t<li>'j93'</li>\n",
       "\t<li>'j91'</li>\n",
       "\t<li>'j64'</li>\n",
       "\t<li>'j43'</li>\n",
       "\t<li>'j82'</li>\n",
       "\t<li>'j1'</li>\n",
       "</ol>\n",
       "</dd>\n",
       "\t<dt>$u21555</dt>\n",
       "\t\t<dd><ol class=list-inline>\n",
       "\t<li>'j81'</li>\n",
       "\t<li>'j76'</li>\n",
       "\t<li>'j72'</li>\n",
       "\t<li>'j97'</li>\n",
       "\t<li>'j83'</li>\n",
       "\t<li>'j74'</li>\n",
       "\t<li>'j87'</li>\n",
       "\t<li>'j85'</li>\n",
       "\t<li>'j90'</li>\n",
       "\t<li>'j96'</li>\n",
       "\t<li>'j89'</li>\n",
       "\t<li>'j93'</li>\n",
       "\t<li>'j84'</li>\n",
       "\t<li>'j91'</li>\n",
       "\t<li>'j82'</li>\n",
       "</ol>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$u7904] \\begin{enumerate*}\n",
       "\\item 'j28'\n",
       "\\item 'j38'\n",
       "\\item 'j14'\n",
       "\\item 'j26'\n",
       "\\item 'j22'\n",
       "\\item 'j3'\n",
       "\\item 'j34'\n",
       "\\item 'j10'\n",
       "\\item 'j100'\n",
       "\\item 'j89'\n",
       "\\item 'j80'\n",
       "\\item 'j52'\n",
       "\\item 'j70'\n",
       "\\item 'j77'\n",
       "\\item 'j51'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item[\\$u20747] \\begin{enumerate*}\n",
       "\\item 'j83'\n",
       "\\item 'j89'\n",
       "\\item 'j93'\n",
       "\\item 'j91'\n",
       "\\item 'j92'\n",
       "\\item 'j72'\n",
       "\\item 'j84'\n",
       "\\item 'j97'\n",
       "\\item 'j100'\n",
       "\\item 'j98'\n",
       "\\item 'j78'\n",
       "\\item 'j87'\n",
       "\\item 'j81'\n",
       "\\item 'j82'\n",
       "\\item 'j86'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item[\\$u4519] \\begin{enumerate*}\n",
       "\\item 'j89'\n",
       "\\item 'j88'\n",
       "\\item 'j87'\n",
       "\\item 'j72'\n",
       "\\item 'j91'\n",
       "\\item 'j92'\n",
       "\\item 'j84'\n",
       "\\item 'j80'\n",
       "\\item 'j83'\n",
       "\\item 'j81'\n",
       "\\item 'j71'\n",
       "\\item 'j73'\n",
       "\\item 'j79'\n",
       "\\item 'j75'\n",
       "\\item 'j78'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item[\\$u13802] \\begin{enumerate*}\n",
       "\\item 'j72'\n",
       "\\item 'j93'\n",
       "\\item 'j80'\n",
       "\\item 'j75'\n",
       "\\item 'j87'\n",
       "\\item 'j89'\n",
       "\\item 'j91'\n",
       "\\item 'j81'\n",
       "\\item 'j100'\n",
       "\\item 'j76'\n",
       "\\item 'j79'\n",
       "\\item 'j77'\n",
       "\\item 'j90'\n",
       "\\item 'j97'\n",
       "\\item 'j73'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item[\\$u7722] \\begin{enumerate*}\n",
       "\\item 'j87'\n",
       "\\item 'j83'\n",
       "\\item 'j86'\n",
       "\\item 'j3'\n",
       "\\item 'j89'\n",
       "\\item 'j76'\n",
       "\\item 'j72'\n",
       "\\item 'j78'\n",
       "\\item 'j92'\n",
       "\\item 'j93'\n",
       "\\item 'j91'\n",
       "\\item 'j64'\n",
       "\\item 'j43'\n",
       "\\item 'j82'\n",
       "\\item 'j1'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item[\\$u21555] \\begin{enumerate*}\n",
       "\\item 'j81'\n",
       "\\item 'j76'\n",
       "\\item 'j72'\n",
       "\\item 'j97'\n",
       "\\item 'j83'\n",
       "\\item 'j74'\n",
       "\\item 'j87'\n",
       "\\item 'j85'\n",
       "\\item 'j90'\n",
       "\\item 'j96'\n",
       "\\item 'j89'\n",
       "\\item 'j93'\n",
       "\\item 'j84'\n",
       "\\item 'j91'\n",
       "\\item 'j82'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$u7904\n",
       ":   1. 'j28'\n",
       "2. 'j38'\n",
       "3. 'j14'\n",
       "4. 'j26'\n",
       "5. 'j22'\n",
       "6. 'j3'\n",
       "7. 'j34'\n",
       "8. 'j10'\n",
       "9. 'j100'\n",
       "10. 'j89'\n",
       "11. 'j80'\n",
       "12. 'j52'\n",
       "13. 'j70'\n",
       "14. 'j77'\n",
       "15. 'j51'\n",
       "\n",
       "\n",
       "\n",
       "$u20747\n",
       ":   1. 'j83'\n",
       "2. 'j89'\n",
       "3. 'j93'\n",
       "4. 'j91'\n",
       "5. 'j92'\n",
       "6. 'j72'\n",
       "7. 'j84'\n",
       "8. 'j97'\n",
       "9. 'j100'\n",
       "10. 'j98'\n",
       "11. 'j78'\n",
       "12. 'j87'\n",
       "13. 'j81'\n",
       "14. 'j82'\n",
       "15. 'j86'\n",
       "\n",
       "\n",
       "\n",
       "$u4519\n",
       ":   1. 'j89'\n",
       "2. 'j88'\n",
       "3. 'j87'\n",
       "4. 'j72'\n",
       "5. 'j91'\n",
       "6. 'j92'\n",
       "7. 'j84'\n",
       "8. 'j80'\n",
       "9. 'j83'\n",
       "10. 'j81'\n",
       "11. 'j71'\n",
       "12. 'j73'\n",
       "13. 'j79'\n",
       "14. 'j75'\n",
       "15. 'j78'\n",
       "\n",
       "\n",
       "\n",
       "$u13802\n",
       ":   1. 'j72'\n",
       "2. 'j93'\n",
       "3. 'j80'\n",
       "4. 'j75'\n",
       "5. 'j87'\n",
       "6. 'j89'\n",
       "7. 'j91'\n",
       "8. 'j81'\n",
       "9. 'j100'\n",
       "10. 'j76'\n",
       "11. 'j79'\n",
       "12. 'j77'\n",
       "13. 'j90'\n",
       "14. 'j97'\n",
       "15. 'j73'\n",
       "\n",
       "\n",
       "\n",
       "$u7722\n",
       ":   1. 'j87'\n",
       "2. 'j83'\n",
       "3. 'j86'\n",
       "4. 'j3'\n",
       "5. 'j89'\n",
       "6. 'j76'\n",
       "7. 'j72'\n",
       "8. 'j78'\n",
       "9. 'j92'\n",
       "10. 'j93'\n",
       "11. 'j91'\n",
       "12. 'j64'\n",
       "13. 'j43'\n",
       "14. 'j82'\n",
       "15. 'j1'\n",
       "\n",
       "\n",
       "\n",
       "$u21555\n",
       ":   1. 'j81'\n",
       "2. 'j76'\n",
       "3. 'j72'\n",
       "4. 'j97'\n",
       "5. 'j83'\n",
       "6. 'j74'\n",
       "7. 'j87'\n",
       "8. 'j85'\n",
       "9. 'j90'\n",
       "10. 'j96'\n",
       "11. 'j89'\n",
       "12. 'j93'\n",
       "13. 'j84'\n",
       "14. 'j91'\n",
       "15. 'j82'\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$u7904\n",
       " [1] \"j28\"  \"j38\"  \"j14\"  \"j26\"  \"j22\"  \"j3\"   \"j34\"  \"j10\"  \"j100\" \"j89\" \n",
       "[11] \"j80\"  \"j52\"  \"j70\"  \"j77\"  \"j51\" \n",
       "\n",
       "$u20747\n",
       " [1] \"j83\"  \"j89\"  \"j93\"  \"j91\"  \"j92\"  \"j72\"  \"j84\"  \"j97\"  \"j100\" \"j98\" \n",
       "[11] \"j78\"  \"j87\"  \"j81\"  \"j82\"  \"j86\" \n",
       "\n",
       "$u4519\n",
       " [1] \"j89\" \"j88\" \"j87\" \"j72\" \"j91\" \"j92\" \"j84\" \"j80\" \"j83\" \"j81\" \"j71\" \"j73\"\n",
       "[13] \"j79\" \"j75\" \"j78\"\n",
       "\n",
       "$u13802\n",
       " [1] \"j72\"  \"j93\"  \"j80\"  \"j75\"  \"j87\"  \"j89\"  \"j91\"  \"j81\"  \"j100\" \"j76\" \n",
       "[11] \"j79\"  \"j77\"  \"j90\"  \"j97\"  \"j73\" \n",
       "\n",
       "$u7722\n",
       " [1] \"j87\" \"j83\" \"j86\" \"j3\"  \"j89\" \"j76\" \"j72\" \"j78\" \"j92\" \"j93\" \"j91\" \"j64\"\n",
       "[13] \"j43\" \"j82\" \"j1\" \n",
       "\n",
       "$u21555\n",
       " [1] \"j81\" \"j76\" \"j72\" \"j97\" \"j83\" \"j74\" \"j87\" \"j85\" \"j90\" \"j96\" \"j89\" \"j93\"\n",
       "[13] \"j84\" \"j91\" \"j82\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### The recommendations for 5 user will be given like \n",
    "rec_list[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number_of_items\n",
       "  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15 \n",
       "287   5   2   1   2   3   1   1   4   2   2   2   3   3   5 726 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### We perceive what number of proposals are created for all the test users by running the next code block:\n",
    "number_of_items = sort(unlist(lapply(rec_list, length)), decreasing = TRUE)\n",
    "table(number_of_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above outcomes, we see that for 287 clients, zero suggestions were created. The reason is that they have appraised every one of the movies in the first dataset. For 726 users, 15 ratings for every one of them has been created. The reason is that in the first dataset, they have not rated for any movies. Different users who have gotten 2, 3, 4, etc. recommendation implies that they have recommended not very many movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Analyzing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  36   37   38   39   40   41   42   43   44   45   46   47   48   49   50   51 \n",
       " 114   77   80   78   74   70   74   75   80   81   70   60   69   61   62   47 \n",
       "  52   53   54   55   56   57   58   59   60   61   62   63   64   65   66   67 \n",
       "  42   52   52   48   56   54   34   43   48   41   42   42   41   53   51   39 \n",
       "  68   69   70   71   72   73   74   75   76   77   78   79   80   81   82   83 \n",
       "  39   29   87  221  364  312  131   48   36   19   33   32   38   20   19   18 \n",
       "  84   85   86   87   88   89   90   91   92   93   94   95   96   97   98   99 \n",
       "  15   23   21   12   12   11   14   16   10   12   12   11   16   13    8   16 \n",
       " 100 \n",
       "1422 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(rowCounts(Jester5k)) ### This code will give us the number of ratings given to each joke:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By investigating the number of appraisals given by every one of the users for the jokes, we can see that there are 1422 individuals who have appraised each of the 100 jokes, which is by all accounts bizarre as there are not many individuals who have appraised 80 to 99 jokes. Further dissecting the jokes we find that there are 221, 364, 312, and 131 clients who have appraised 71, 72, 73, and 74 jokes individually which are by all accounts unordinary contrasted with other joke evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>3399</li>\n",
       "\t<li>100</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 3399\n",
       "\\item 100\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 3399\n",
       "2. 100\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 3399  100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### For next step we will evacuate the ratings of clients who have appraised at least 60 jokes as \n",
    "model_data = Jester5k[rowCounts(Jester5k) > 60]\n",
    "dim(model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The measurement has been diminished from 5000 to 3339 records. Presently how about we investigate the normal ratings given by every client. A boxplot demonstrates to us the normal appropriation of the joke evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nQYCQIEBIECAkCPgf1R5C/AYkrPwAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot(rowMeans(model_data [rowMeans(model_data)>=-10 & rowMeans(model_data)<=\n",
    "10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous plot demonstrates to us that there are not very many evaluations that veer off from typical conduct. From the previous picture, we see that the normal evaluations that are over 7 (around) and underneath -5 (roughly) are somewhat exceptions and are less in number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM\njIyampqnp6eysrK9vb3Hx8fQ0NDZ2dnh4eHp6enw8PD////QFLu4AAAACXBIWXMAABJ0AAAS\ndAHeZh94AAARmklEQVR4nO3d7XKUV5KF0beQxIeMxP3fbWMMHnqmG054dmZB5lo/FLIdrvJO\n8QRSSbavT8D/23XvfwCYQEgQICQIEBIECAkChAQBQoIAIUGAkCBASBAgJAgQEgQICQKEBAFC\nggAhQYCQIEBIECAkCBASBAgJAoQEAUKCACFBgJAgQEgQICQIEBIECAkChAQBQoIAIUGAkCBA\nSBAgJAgQEgQICQKEBAFCggAhQYCQIEBIECAkCBASBAgJAoQEAUKCACFBgJAgQEgQICQIEBIE\nCAkChAQBQoIAIUGAkCBASBAgJAgQEgQICQKEBAFCggAhQYCQIEBIECAkCBASBAgJAoQEAUKC\nACFBgJAgQEgQICQIEBIECAkChAQBQoIAIUGAkCBASBAgJAgQEgQICQKEBAFCggAhQYCQIEBI\nECAkCBASBAgJAoQEAUKCACFBgJAgoCGkC34z/+BXeT6cOzwFJAkJAoQEAUKCACFBgJAgQEgQ\nICQIEBIECAkChAQBQoIAIUGAkCBASBAgJAgQEgQICQKEBAFCggAhQYCQIEBIv5V7/zenfGD+\nGyGt4rBVhLSKw1YR0ioOW0VIqzhsFSFBgJAgQEgQIKRVHLaKkFZx2CpCWsVhqwhpFYetIqRV\nHLaKkCBASBAgJAgQ0ioOW0VIqzhsFSGt4rBVhLSKw1YR0ioOW0VIECAkCBASBAhpFYetIqRV\nHLaKkFZx2CpCWsVhqwhpFYetIiQIEBIECAkChLSKw1YR0ioOW0VIqzhsFSGt4rBVhLSKw1YR\nEgQICQKEBAFCWsVhqwhpFYetIqRVHLZKZ0ivb2+f3757c10PH4qegh9z2CqNIb3cruvT6+c3\nf3ooeQp+wmGrNIb0dD2+fn7z9PK5qafrbcVTwJ00hnRdr1/ffP4s77pVPAXcSWtIn9/cru/+\n4H/95e/8w6eAO2n91O7jp0/v/nzz5+9IP/wiSUhFHLZKY0gfr9vbj58eb59Len5zPVc8BT/h\nsFU6X/5+vv3P527vap6CH3PYKr3fkP3w9ObPih7fvZQ9BT/isFX8ZMMqDltFSBAgJAgQEgQI\naRWHrSKkVRy2ipBWcdgqQlrFYasIaRWHrSIkCBASBAgJAoS0isNWEdIqDltFSKs4bBUhreKw\nVYS0isNWERIECAkChAQBQlrFYasIaRWHrSKkVRy2ipBWcdgqQlrFYasICQKEBAFCggAhreKw\nVYS0isNWEdIqDltFSKs4bBUhreKwVYQEAUKCACFBgJBWcdgqQlrFYasIaRWHrSKkVRy2ipBW\ncdgqQoIAIUGAkCBASKs4bBUhreKwVYS0isNWEdIqDltFSKs4bBUhQYCQIEBIECCkVRy2ipBW\ncdgqQlrFYasIaRWHrSKkVRy2ipAgQEgQICQIENIqDltFSKs4bBUhreKwVYS0isNWEdIqDltF\nSBAgJAgQEgQIaRWHrSKkVRy2ipBWcdgqQlrFYasIaRWHrSIkCBASBAgJAoS0isNWEdIqDltF\nSKs4bBUhreKwVYS0isNWERIECAkChAQBQlrFYasIaRWHrSKkVRy2yl1Cun72ED7eRRy2ipBW\ncdgqjSFd/67iKeBOGkP64yYkpur81O718Xp4+fII/+khjiuDX0/v10gfruvDJ18j3Y/DVml+\nseHl4Xp8FdLdOGyV9lft3l23ZyHdi8NW6X/5++Obn38N5ONdxGGr3OP7SE9CuheHreJHhCBA\nSBAgJAgQ0ioOW0VIqzhsFSGt4rBVhLSKw1YR0ioOW0VIECAkCBASBAhpFYetIqRVHLaKkFZx\n2CpCWsVhqwhpFYetIiQIEBIECAkChLSKw1YR0ioOW0VIqzhsFSGt4rBVhLSKw1YREgQICQKE\nBAFCWsVhqwhpFYetIqRVHLaKkFZx2CpCWsVhqwgJAoQEAUKCACGt4rBVhLSKw1YR0ioOW0VI\nqzhsFSGt4rBVhAQBQoIAIUGAkFZx2CpCWsVhqwhpFYetIqRVHLaKkFZx2CpCggAhQYCQIEBI\nqzhsFSGt4rBVhLSKw1YR0ioOW0VIqzhsFSFBgJAgQEgQIKRVHLaKkFZx2CpCWsVhqwhpFYet\nIqRVHLaKkCBASBAgJAgQ0ioOW0VIqzhsFSG1ura79wegjJBajR12aO5+IbUaO+zQ3P1CajV2\n2KG5+4XUauywQ3P3C6nV2GGH5u4XUquxww7N3S+kVmOHHZq7X0itxg47NHe/kFqNHXZo7n4h\ntRo77NDc/UJqNXbYobn7hdRq7LBDc/cLqdXYYYfm7hdSq7HDDs3dL6RWY4cdmrtfSK3GDjs0\nd39nSK9P1/Xw/PVBfvgoY+89dtihufsbQ3q9ffl3JB//ehAhbTR3f2NIb6/3n2t6f3v48iBC\n2mju/saQbn/9jS+3Ny9CWmru/saQvrXz+vDwn0Ja8d/IGDvs0Nz9jSG9uV6/vffgd6Sd5u5v\nDOn99fT1vZfrQUgrzd3f+fL327/ref7JZ29j7z122KG5+1u/Ifvx8dt7L09C2mjufj/Z0Grs\nsENz9wup1dhhh+buF1KrscMOzd0vpFZjhx2au19IrcYOOzR3v5BajR12aO5+IbUaO+zQ3P1C\najV22KG5+4XUauywQ3P3C6nV2GGH5u4XUquxww7N3S+kVmOHHZq7X0itxg47NHe/kFqNHXZo\n7n4htRo77NDc/UJqNXbYobn7hdRq7LBDc/cLqdXYYYfm7hdSq7HDDs3dL6RWY4cdmrtfSK3G\nDjs0d7+QWo0ddmjufiG1Gjvs0Nz9Qmo1dtihufuF1GrssENz9wup1dhhh+buF1KrscMOzd0v\npFZjhx2au19IrcYOOzR3v5BajR12aO5+IbUaO+zQ3P1CajV22KG5+4XUauywQ3P3C6nV2GGH\n5u4XUquxww7N3S+kVmOHHZq7X0itxg47NHe/kFqNHXZo7n4htRo77NDc/UJqNXbYobn7hdRq\n7LBDc/cLqdXYYYfm7hdSq7HDDs3dL6RWY4cdmrtfSK3GDjs0d7+QWo0ddmjufiG1Gjvs0Nz9\nQmo1dtihufuF1GrssENz9wup1bXdvT8AZYTU6t6/ju/u3h+AMkJqde9fx3d37w9AGSG1Gjvs\n0Nz9Qmo1dtihufuF1GrssENz9wup1dhhh+buF1KrscMOzd0vpFZjhx2au19IrcYOOzR3v5Ba\njR12aO5+IbUaO+zQ3P1CajV22KG5+4XUauywQ3P3C6nV2GGH5u4XUquxww7N3S+kVmOHHZq7\nX0itxg47NHe/kFqNHXZo7n4htRo77NDc/UJqNXbYobn7hdRq7LBDc/cLqdXYYYfm7hdSq7HD\nDs3dL6RWY4cdmrtfSK3GDjs0d7+QWo0ddmjufiG1Gjvs0Nz9Qmo1dtihufuF1GrssENz9wup\n1dhhh+buF1KrscMOzd0vpFZjhx2au19IrcYOOzR3v5BajR12aO5+IbUaO+zQ3P1CajV22KG5\n+4XUauywQ3P3t4b0x7vHL/8j0ce3f1Q9xS9u7LBDc/c3hvT65rv/Ke9DyVP88sYOOzR3f2NI\nb6/bh49f3nt5vl1vK57ilzd22KG5+xtDul0f/37/43WreIpf3thhh+bubwzpuv7bH3z9M9/5\nh0/xyxs77NDc/X5HajV22KG5+3u/Rnp++fKer5G2mru/8+Xvh+8+d3vzWvIUv7qxww7N3d/7\nfaS3X76PdHt85/tIO83d7ycbWo0ddmjufiG1Gjvs0Nz9Qmo1dtihufuF1GrssENz9wup1dhh\nh+buF1KrscMOzd0vpFZjhx2au19IrcYOOzR3v5BajR12aO5+IbUaO+zQ3P1CajV22KG5+4XU\nauywQ3P3C6nV2GGH5u4XUquxww7N3S+kVmOHHZq7X0itxg47NHe/kFqNHXZo7n4htRo77NDc\n/UJqNXbYobn7hdRq7LBDc/cLqdXYYYfm7hdSq7HDDs3dL6RWY4cdmrtfSK3GDjs0d7+QWo0d\ndmjufiG1Gjvs0Nz9Qmp1bXfvD0AZIUGAkCBASKs4bBUhreKwVYS0isNWEdIqDltFSKs4bBUh\nQYCQIEBIECCkVRy2ipBWcdgqQlrFYasIaRWHrSKkVRy2ipAgQEgQICQIENIqDltFSKs4bBUh\nreKwVYS0isNWEdIqDltFSBAgJAgQEgQIaRWHrSKkVRy2ipBWcdgqQlrFYasIaRWHrSIkCBAS\nBAgJAoS0isNWEdIqDltFSKs4bBUhreKwVYS0isNWERIECAkChAQBQlrFYasIaRWHrSKkVRy2\nipBWcdgqQlrFYasICQKEBAFCggAhreKwVYS0isNWEdIqDltFSKs4bBUhreKwVTpDen26rofn\nrw/yw0fx8eY30xjS6+360+NfDyIkJmkM6e31/nNN728PXx5ESEzSGNLtr7/x5fbmRUh34rBV\nGkP61s7rw4OQ7sRhqzSG9OZ6/fbeg5Duw2GrNIb0/nr6+t7L9SCku3DYKp0vf7/9u57nS0h3\n4bBVWr8h+/Hx23svT//nUa7v/eOngLvwkw0QICQIuEdIP//MTUhFHLaKkFZx2CpCWsVhqwhp\nFYetIqRVHLaKkCDAy98QICQIENIqDltFSKs4bBUhreKwVYS0isNWEdIqDltFSBAgJAgQEgQI\naRWHrSKkVRy2ipBWcdgqQlrFYasIaRWHrSIkCBASBAgJAoS0isNWEdIqDltFSKs4bBUhreKw\nVYS0isNWERIECAkChAQBQlrFYasIaRWHrSKkVRy2ipBWcdgqQlrFYasICQKEBAFCggAhreKw\nVYS0isNWEdIqDltFSKs4bBUhreKwVYQEAUKCACFBgJBWcdgqQlrFYasIaRWHrSKkVRy2ipBW\ncdgqQoIAIUGAkCBASKs4bBUhreKwVYS0isNWEdIqDltFSKs4bBUhQYCQIEBIECCkVRy2ipBW\ncdgqQlrFYasIaRWHrSKkVRy2ipAgQEgQICQIENIqDltFSKs4bBUhreKwVYS0isNWEdIqDltF\nSBAgJAgQEgQIaRWHrSKkVRy2ipBWcdgqQlrFYasIaRWHrXKXkK6fPYSPN78ZIUFAY0jXv6t4\nCriTxpD+uAnp3hy2Suendq+P18PLl0fwqd2dOGyV3q+RPlzXh09Cuh+HrdL8YsPLw/X4KqS7\ncdgq7a/avbtuz0K6F4et0v/y98c3//mVhuNXIuDXc4/vIz35HYlp/IgQBNwjpJ9/5iakIg5b\nRUirOGwVIa3isFWEtIrDVhHSKg5bRUgQ4OVvCBASBAhpFYetIqRVHLaKkFZx2CpCWsVhqwhp\nFYetIiQIEBIECAkChLSKw1YR0ioOW0VIqzhsFSGt4rBVhLSKw1YREgQICQKEBAFCWsVhqwhp\nFYetIqRVHLaKkFZx2CpCWsVhqwgJAoQEAUKCACGt4rBVhLSKw1YR0ioOW0VIqzhsFSGt4rBV\nhAQBQoIAIUGAkFZx2CpCWsVhqwhpFYetIqRVHLaKkH4r173d+wC/LCFBgJAgQEgQICQIEBIE\nCAkChAQBQoIAIUGAkCBASBAgJAgQEgQICQKEBAFCggAhQYCQIEBIECAkCBASBAgJAn7RkOA3\n8w9+lefDgX2EBAFCggAhQYCQIEBIECAkCBASBAgJAoQEAUKCACFBgJAgQEgQICQIEBIECAkC\nhAQBQoIAIUGAkCBASBAgJAgQEgQICQKEBAFCggAhQYCQIEBIECAkCBASBAgJAoQEAUKCACFB\ngJAgQEgQICQIEBIECAkChAQBQoIAIUGAkCBASBAgJAgQEgQICQKEBAFCggAhQYCQIEBIECAk\nCBASBAgJAoQEAUKCACFBgJAgQEgQICQIEBIECAkChAQBQoIAIUGAkCBASBAgJAgQEgQICQKE\nBAFCggAhQYCQIEBIECAkCBASBAgJAoQEAUKCACFBgJAgQEgQICQIEBIECAkChAQBQoIAIUGA\nkCBASBAgJAgQEgQICQKEBAFCggAhQYCQIEBIECAkCBASBAgJAoQEAUKCACFBgJAgQEgQICQI\nEBIECAkChAQBQoIAIUGAkCBASBAgJAgQEgQICQKEBAH/AhlLWiryPcyTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot(rowMeans(model_data [rowMeans(model_data)>=-5 & rowMeans(model_data)<=7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>3300</li>\n",
       "\t<li>100</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 3300\n",
       "\\item 100\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 3300\n",
       "2. 100\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 3300  100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To drop clients who have given exceptionally low normal appraisals and high normal evaluations. \n",
    "model_data = model_data [rowMeans(model_data)>=-5 & rowMeans(model_data)<= 7]\n",
    "dim(model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should inspect the rating conveyance of the initial 100 clients in the information as pursues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAclBMVEUAAAAAAM0YGMwcHMw0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\nMkiWVUEGybIq6P8D4hV02carO3kAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image(model_data[1:100], main = \"Rating Distribution of 100 users\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Creating the Recommendation Model With the k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We utilize cross-validation strategy to part the information, for instance, the 5-overlay cross-validation approach separates the preparation information into five smaller sets where four sets will be used for training the model and the staying one set is utilized for testing the model. We should characterize the parameters into least great appraisals, the number of folds for cross-approval technique, and split technique as pursues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_to_keep <- 30 ### items_to_keep defines the base number of items to use to produce\n",
    "rating_threshold <- 3 ### rating_threshold defines the minimum raitng that is that is acknowledged as favorable rating\n",
    "n_fold <- 5  ### n_fold defines the cross-validaton. 4 training sets out of 5 and 1 test set\n",
    "eval_sets <- evaluationScheme(data = model_data, method = \"cross-validation\",\n",
    "                              train = percentage_training, given = items_to_keep, \n",
    "                              goodRating = rating_threshold, k = n_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>2640</li>\n",
       "\t<li>2640</li>\n",
       "\t<li>2640</li>\n",
       "\t<li>2640</li>\n",
       "\t<li>2640</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2640\n",
       "\\item 2640\n",
       "\\item 2640\n",
       "\\item 2640\n",
       "\\item 2640\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2640\n",
       "2. 2640\n",
       "3. 2640\n",
       "4. 2640\n",
       "5. 2640\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 2640 2640 2640 2640 2640"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Five sets made by the crossvalidation approach\n",
    "size_sets <- sapply(eval_sets@runsTrain, length)\n",
    "size_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as to remove the sets, we have to utilize getData() function. There are three sets; \"train\" is the training set, \"known\"  is the test set, with the item used to build the recommendations, \"unknown\" is the test set, with the item used to test the recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2640 x 100 rating matrix of class 'realRatingMatrix' with 223401 ratings."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "660 x 100 rating matrix of class 'realRatingMatrix' with 19800 ratings."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "660 x 100 rating matrix of class 'realRatingMatrix' with 36562 ratings."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getData(eval_sets,\"train\")\n",
    "getData(eval_sets,\"known\")\n",
    "getData(eval_sets,\"unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Designing User-Based Collaborative Filtering\n",
    "Presently we assess the models, we should set the parameters model_to_evaluate with user-based community oriented separating and model_parameters with NULL for utilizing default settings as pursues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_evaluate <- \"UBCF\"\n",
    "model_parameters <- NULL\n",
    "\n",
    "### We will build the recommender model using \"recommender()\" function, such as\n",
    "eval_recommender <- Recommender(data = getData(eval_sets,\"train\"),\n",
    "                                method = model_to_evaluate,\n",
    "                               parameter = model_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that the user-based recommender model has been scholarly with preparation information of 2640 clients. Presently we can foresee the known ratings in eval_sets and assess the outcomes with obscure sets as portrayed before. Prior to making the forecasts for the known appraisals, we need to set the number of things to be suggested. Next, we need to give the test set to the predict() work for expectation. The expectation of evaluations is finished by running the code;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "660 x 100 rating matrix of class 'realRatingMatrix' with 46200 ratings."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "items_to_recommend <- 20\n",
    "eval_prediction <- predict(object = eval_recommender, newdata = getData(eval_sets,\n",
    "                          \"known\"), n = items_to_recommend, type = \"ratings\")\n",
    "eval_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing the predict() function will be costly because the user-based collaborative filtering approach is memory-based and a lazy learning system actualized at run time, to appear that the entire dataset is stacked amid the expectation. \n",
    "\n",
    "Now we will assess the expectations with the unknown sets and estimate the model exactness with measurements. For example, precision, recall, and F1 measure. The next code measures the model precision measurements by calling the calcPredicitonAccuracy() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 6 × 3 of type dbl[,3]</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>RMSE</th><th scope=col>MSE</th><th scope=col>MAE</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>u15221</th><td>2.781407</td><td> 7.736225</td><td>2.124533</td></tr>\n",
       "\t<tr><th scope=row>u16636</th><td>3.386843</td><td>11.470704</td><td>2.869025</td></tr>\n",
       "\t<tr><th scope=row>u12843</th><td>3.932626</td><td>15.465545</td><td>3.343523</td></tr>\n",
       "\t<tr><th scope=row>u17322</th><td>4.671722</td><td>21.824983</td><td>3.789692</td></tr>\n",
       "\t<tr><th scope=row>u13610</th><td>4.700150</td><td>22.091405</td><td>3.749364</td></tr>\n",
       "\t<tr><th scope=row>u3970</th><td>5.579059</td><td>31.125897</td><td>4.640190</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 6 × 3 of type dbl{[},3{]}\n",
       "\\begin{tabular}{r|lll}\n",
       "  & RMSE & MSE & MAE\\\\\n",
       "\\hline\n",
       "\tu15221 & 2.781407 &  7.736225 & 2.124533\\\\\n",
       "\tu16636 & 3.386843 & 11.470704 & 2.869025\\\\\n",
       "\tu12843 & 3.932626 & 15.465545 & 3.343523\\\\\n",
       "\tu17322 & 4.671722 & 21.824983 & 3.789692\\\\\n",
       "\tu13610 & 4.700150 & 22.091405 & 3.749364\\\\\n",
       "\tu3970 & 5.579059 & 31.125897 & 4.640190\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 6 × 3 of type dbl[,3]\n",
       "\n",
       "| <!--/--> | RMSE | MSE | MAE |\n",
       "|---|---|---|---|\n",
       "| u15221 | 2.781407 |  7.736225 | 2.124533 |\n",
       "| u16636 | 3.386843 | 11.470704 | 2.869025 |\n",
       "| u12843 | 3.932626 | 15.465545 | 3.343523 |\n",
       "| u17322 | 4.671722 | 21.824983 | 3.789692 |\n",
       "| u13610 | 4.700150 | 22.091405 | 3.749364 |\n",
       "| u3970 | 5.579059 | 31.125897 | 4.640190 |\n",
       "\n"
      ],
      "text/plain": [
       "       RMSE     MSE       MAE     \n",
       "u15221 2.781407  7.736225 2.124533\n",
       "u16636 3.386843 11.470704 2.869025\n",
       "u12843 3.932626 15.465545 3.343523\n",
       "u17322 4.671722 21.824983 3.789692\n",
       "u13610 4.700150 22.091405 3.749364\n",
       "u3970  5.579059 31.125897 4.640190"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_accuracy <- calcPredictionAccuracy( x = eval_prediction, data = getData(eval_sets, \"unknown\"), byUser = TRUE)\n",
    "head(eval_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting byUser = TRUE, we are figuring the model exactness for every client. Taking the normal will give us the general exactness as pursues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>RMSE</dt>\n",
       "\t\t<dd>4.11900388606753</dd>\n",
       "\t<dt>MSE</dt>\n",
       "\t\t<dd>18.6474987725582</dd>\n",
       "\t<dt>MAE</dt>\n",
       "\t\t<dd>3.38894269998099</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[RMSE] 4.11900388606753\n",
       "\\item[MSE] 18.6474987725582\n",
       "\\item[MAE] 3.38894269998099\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "RMSE\n",
       ":   4.11900388606753MSE\n",
       ":   18.6474987725582MAE\n",
       ":   3.38894269998099\n",
       "\n"
      ],
      "text/plain": [
       "     RMSE       MSE       MAE \n",
       " 4.119004 18.647499  3.388943 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "apply(eval_accuracy,2,mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting byUser=FALSE, in the past calcPredictionAccuracy() we can ascertain the by and large model precision given by the accompanying:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>RMSE</dt>\n",
       "\t\t<dd>4.34228220698213</dd>\n",
       "\t<dt>MSE</dt>\n",
       "\t\t<dd>18.8554147650736</dd>\n",
       "\t<dt>MAE</dt>\n",
       "\t\t<dd>3.4097419891538</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[RMSE] 4.34228220698213\n",
       "\\item[MSE] 18.8554147650736\n",
       "\\item[MAE] 3.4097419891538\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "RMSE\n",
       ":   4.34228220698213MSE\n",
       ":   18.8554147650736MAE\n",
       ":   3.4097419891538\n",
       "\n"
      ],
      "text/plain": [
       "     RMSE       MSE       MAE \n",
       " 4.342282 18.855415  3.409742 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_accuracy <- calcPredictionAccuracy(x = eval_prediction, data = getData(eval_sets,\"unknown\"), byUser = FALSE)\n",
    "eval_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where RMSE means <b>Root Mean Square Error</b>, MSE means <b>Mean Square Error</b>, and MAE means <b>Mean Absolute Error</b>. We can likewise assess the model exactness utilizing precision/recall. For this, we utilize the evaluate() capacity and afterward the consequence of the evaluate() technique is utilized to make a confusion matrix containing accuracy/review/f1 measures as pursues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UBCF run fold/sample [model time/prediction time]\n",
      "\t 1  [0.03sec/2.69sec] \n",
      "\t 2  [0.03sec/2.65sec] \n",
      "\t 3  [0.01sec/2.7sec] \n",
      "\t 4  [0.02sec/2.59sec] \n",
      "\t 5  [0.03sec/2.53sec] \n"
     ]
    }
   ],
   "source": [
    "results <- evaluate(x = eval_sets, method = model_to_evaluate, n = seq(1, 100, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 6 × 8 of type dbl[,8]</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>TP</th><th scope=col>FP</th><th scope=col>FN</th><th scope=col>TN</th><th scope=col>precision</th><th scope=col>recall</th><th scope=col>TPR</th><th scope=col>FPR</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td> 0.6227273</td><td> 0.3772727</td><td>20.874242</td><td>48.12576</td><td>0.6227273</td><td>0.03744411</td><td>0.03744411</td><td>0.007160292</td></tr>\n",
       "\t<tr><th scope=row>6</th><td> 3.4939394</td><td> 2.5060606</td><td>18.003030</td><td>45.99697</td><td>0.5823232</td><td>0.19642324</td><td>0.19642324</td><td>0.048318247</td></tr>\n",
       "\t<tr><th scope=row>11</th><td> 6.0469697</td><td> 4.9530303</td><td>15.450000</td><td>43.55000</td><td>0.5497245</td><td>0.32746806</td><td>0.32746806</td><td>0.096602980</td></tr>\n",
       "\t<tr><th scope=row>16</th><td> 8.1242424</td><td> 7.8757576</td><td>13.372727</td><td>40.62727</td><td>0.5077652</td><td>0.42417064</td><td>0.42417064</td><td>0.154024010</td></tr>\n",
       "\t<tr><th scope=row>21</th><td> 9.9272727</td><td>11.0727273</td><td>11.569697</td><td>37.43030</td><td>0.4727273</td><td>0.50352192</td><td>0.50352192</td><td>0.217074013</td></tr>\n",
       "\t<tr><th scope=row>26</th><td>11.5181818</td><td>14.4818182</td><td> 9.978788</td><td>34.02121</td><td>0.4430070</td><td>0.57256803</td><td>0.57256803</td><td>0.284973501</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 6 × 8 of type dbl{[},8{]}\n",
       "\\begin{tabular}{r|llllllll}\n",
       "  & TP & FP & FN & TN & precision & recall & TPR & FPR\\\\\n",
       "\\hline\n",
       "\t1 &  0.6227273 &  0.3772727 & 20.874242 & 48.12576 & 0.6227273 & 0.03744411 & 0.03744411 & 0.007160292\\\\\n",
       "\t6 &  3.4939394 &  2.5060606 & 18.003030 & 45.99697 & 0.5823232 & 0.19642324 & 0.19642324 & 0.048318247\\\\\n",
       "\t11 &  6.0469697 &  4.9530303 & 15.450000 & 43.55000 & 0.5497245 & 0.32746806 & 0.32746806 & 0.096602980\\\\\n",
       "\t16 &  8.1242424 &  7.8757576 & 13.372727 & 40.62727 & 0.5077652 & 0.42417064 & 0.42417064 & 0.154024010\\\\\n",
       "\t21 &  9.9272727 & 11.0727273 & 11.569697 & 37.43030 & 0.4727273 & 0.50352192 & 0.50352192 & 0.217074013\\\\\n",
       "\t26 & 11.5181818 & 14.4818182 &  9.978788 & 34.02121 & 0.4430070 & 0.57256803 & 0.57256803 & 0.284973501\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 6 × 8 of type dbl[,8]\n",
       "\n",
       "| <!--/--> | TP | FP | FN | TN | precision | recall | TPR | FPR |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| 1 |  0.6227273 |  0.3772727 | 20.874242 | 48.12576 | 0.6227273 | 0.03744411 | 0.03744411 | 0.007160292 |\n",
       "| 6 |  3.4939394 |  2.5060606 | 18.003030 | 45.99697 | 0.5823232 | 0.19642324 | 0.19642324 | 0.048318247 |\n",
       "| 11 |  6.0469697 |  4.9530303 | 15.450000 | 43.55000 | 0.5497245 | 0.32746806 | 0.32746806 | 0.096602980 |\n",
       "| 16 |  8.1242424 |  7.8757576 | 13.372727 | 40.62727 | 0.5077652 | 0.42417064 | 0.42417064 | 0.154024010 |\n",
       "| 21 |  9.9272727 | 11.0727273 | 11.569697 | 37.43030 | 0.4727273 | 0.50352192 | 0.50352192 | 0.217074013 |\n",
       "| 26 | 11.5181818 | 14.4818182 |  9.978788 | 34.02121 | 0.4430070 | 0.57256803 | 0.57256803 | 0.284973501 |\n",
       "\n"
      ],
      "text/plain": [
       "   TP         FP         FN        TN       precision recall     TPR       \n",
       "1   0.6227273  0.3772727 20.874242 48.12576 0.6227273 0.03744411 0.03744411\n",
       "6   3.4939394  2.5060606 18.003030 45.99697 0.5823232 0.19642324 0.19642324\n",
       "11  6.0469697  4.9530303 15.450000 43.55000 0.5497245 0.32746806 0.32746806\n",
       "16  8.1242424  7.8757576 13.372727 40.62727 0.5077652 0.42417064 0.42417064\n",
       "21  9.9272727 11.0727273 11.569697 37.43030 0.4727273 0.50352192 0.50352192\n",
       "26 11.5181818 14.4818182  9.978788 34.02121 0.4430070 0.57256803 0.57256803\n",
       "   FPR        \n",
       "1  0.007160292\n",
       "6  0.048318247\n",
       "11 0.096602980\n",
       "16 0.154024010\n",
       "21 0.217074013\n",
       "26 0.284973501"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(getConfusionMatrix(results)[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- True Positives (TP): These are recommended items that have been rated correctly\n",
    "- False Positives (FP): These are recommended items that haven't been rated\n",
    "- False Negatives (FN): These are not recommended items that have been rated\n",
    "- True Negatives (TN): These are not recommended items that haven't been rated\n",
    "\n",
    "If we need to assess every one of the parts in the meantime, we can simply aggregate up to the files as pursues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 6 × 4 of type dbl[,4]</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>TP</th><th scope=col>FP</th><th scope=col>FN</th><th scope=col>TN</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td> 3.089394</td><td> 1.910606</td><td>104.04697</td><td>240.9530</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>17.581818</td><td>12.418182</td><td> 89.55455</td><td>230.4455</td></tr>\n",
       "\t<tr><th scope=row>11</th><td>30.175758</td><td>24.824242</td><td> 76.96061</td><td>218.0394</td></tr>\n",
       "\t<tr><th scope=row>16</th><td>40.693939</td><td>39.306061</td><td> 66.44242</td><td>203.5576</td></tr>\n",
       "\t<tr><th scope=row>21</th><td>49.424242</td><td>55.575758</td><td> 57.71212</td><td>187.2879</td></tr>\n",
       "\t<tr><th scope=row>26</th><td>57.151515</td><td>72.848485</td><td> 49.98485</td><td>170.0152</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 6 × 4 of type dbl{[},4{]}\n",
       "\\begin{tabular}{r|llll}\n",
       "  & TP & FP & FN & TN\\\\\n",
       "\\hline\n",
       "\t1 &  3.089394 &  1.910606 & 104.04697 & 240.9530\\\\\n",
       "\t6 & 17.581818 & 12.418182 &  89.55455 & 230.4455\\\\\n",
       "\t11 & 30.175758 & 24.824242 &  76.96061 & 218.0394\\\\\n",
       "\t16 & 40.693939 & 39.306061 &  66.44242 & 203.5576\\\\\n",
       "\t21 & 49.424242 & 55.575758 &  57.71212 & 187.2879\\\\\n",
       "\t26 & 57.151515 & 72.848485 &  49.98485 & 170.0152\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 6 × 4 of type dbl[,4]\n",
       "\n",
       "| <!--/--> | TP | FP | FN | TN |\n",
       "|---|---|---|---|---|\n",
       "| 1 |  3.089394 |  1.910606 | 104.04697 | 240.9530 |\n",
       "| 6 | 17.581818 | 12.418182 |  89.55455 | 230.4455 |\n",
       "| 11 | 30.175758 | 24.824242 |  76.96061 | 218.0394 |\n",
       "| 16 | 40.693939 | 39.306061 |  66.44242 | 203.5576 |\n",
       "| 21 | 49.424242 | 55.575758 |  57.71212 | 187.2879 |\n",
       "| 26 | 57.151515 | 72.848485 |  49.98485 | 170.0152 |\n",
       "\n"
      ],
      "text/plain": [
       "   TP        FP        FN        TN      \n",
       "1   3.089394  1.910606 104.04697 240.9530\n",
       "6  17.581818 12.418182  89.55455 230.4455\n",
       "11 30.175758 24.824242  76.96061 218.0394\n",
       "16 40.693939 39.306061  66.44242 203.5576\n",
       "21 49.424242 55.575758  57.71212 187.2879\n",
       "26 57.151515 72.848485  49.98485 170.0152"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns_to_sum <- c(\"TP\", \"FP\", \"FN\", \"TN\")\n",
    "indices_summed <- Reduce(\"+\", getConfusionMatrix(results))[, columns_to_sum]\n",
    "head(indices_summed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since abridging the model is troublesome by alluding to the above table, we can utilize a ROC(Receiver Operating Characteristics) bend to assess the model. Use plot() to assemble the ROC plot as pursues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAk1BMVEUAAAABAQEEBAQFBQUG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\n",
      "text/plain": [
       "Plot with title \"ROC Curve\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(results, annotate = TRUE, main = \"ROC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot demonstrates the connection between True Positive Rate (TPR) and False Positive Rate (FPR). However, we need to pick the qualities so that we give an exchange off among TPR and FPR. For our situation, we see that nn=31 is a generally excellent exchange off since while considering neighbors of 31 we have TPR closer to 0.7, FPR is 0.4 and when moving to nn=36 the TPR is still near 0.6 however the FPR has been changed to 0.4. This implies the False Positive Rate has been expanded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Curve: A graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters:\n",
    "- TPR: True Positive Rate\n",
    "\n",
    "<i>TPR</i> = $\\frac{TP}{TP+FN}$\n",
    "\n",
    "- FPR: False Positive Rate\n",
    "\n",
    "<i>FPR</i> = $\\frac{FP}{FP+TN}$\n",
    "\n",
    "From this graph, it can be easily seen that False Positive Rate increased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Building an Item-based Recommender Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we used in the UBCF, we are going to use the same Jester5k dataset for the IBCF recommender system. We first expel the user information of the individuals who have appraised every one of the items and furthermore those records who have rated more than 60 as pursues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3399 x 100 rating matrix of class 'realRatingMatrix' with 287914 ratings."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(recommenderlab)\n",
    "data(\"Jester5k\")\n",
    "model_data = Jester5k[rowCounts(Jester5k)>60]\n",
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of the average ratings for each of the users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nQYCQIEBIECAkCPgf1R5C/AYkrPwAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boxplot(rowMeans(model_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code computes the mean ratings given by each user and recognizes users who have given outrageous appraisals either extremely high ratings or exceptionally low evaluations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>75</li>\n",
       "\t<li>100</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 75\n",
       "\\item 100\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 75\n",
       "2. 100\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  75 100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(model_data[rowMeans(model_data) < -5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>24</li>\n",
       "\t<li>100</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 24\n",
       "\\item 100\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 24\n",
       "2. 100\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  24 100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(model_data[rowMeans(model_data) >= 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above outputs, we see that there are 24 records with high average ratings furthermore, 75 records with low ratings, contrasted and most of the users. From the complete 3399 records, We will dispose of that 99 records to prepare a reasonable pool without outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3300 x 100 rating matrix of class 'realRatingMatrix' with 279763 ratings."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_data = model_data [rowMeans(model_data) >= -5 & rowMeans(model_data) < 7]\n",
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparing Training and Test Data\n",
    "\n",
    "The initial phase in structure any recommender model is to set up the preparation information. We will divide the dataset into two sets. 20% of the dataset will test set and the other 80% will be training set. We manufacture the recommender model utilizing the training set and create the recommendations on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'logical'"
      ],
      "text/latex": [
       "'logical'"
      ],
      "text/markdown": [
       "'logical'"
      ],
      "text/plain": [
       "[1] \"logical\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "which_train = sample(x = c(TRUE, FALSE), size = nrow(model_data), replace = TRUE, prob = c(0.8, 0.2))\n",
    "class(which_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>FALSE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item FALSE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. TRUE\n",
       "2. TRUE\n",
       "3. TRUE\n",
       "4. FALSE\n",
       "5. TRUE\n",
       "6. TRUE\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(which_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At that point we utilize the logical object in the model_data to create the training set as pursues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>2689</li>\n",
       "\t<li>100</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2689\n",
       "\\item 100\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2689\n",
       "2. 100\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 2689  100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_data_train = model_data[which_train,]\n",
    "dim(model_data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then point we utilize the logical object in the model_data to create the test set as pursues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>611</li>\n",
       "\t<li>100</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 611\n",
       "\\item 100\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 611\n",
       "2. 100\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 611 100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_data_test = model_data[!which_train,]\n",
    "dim(model_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the test and training sets are ready, we are going to train the model and develop the top recommendations for the test set.\n",
    "\n",
    "### 2. Creating an Item-based Collaborative Model\n",
    "We are going to use the same \"recommender()\" function as we made for the UBFC. \n",
    "\n",
    "We set the model to assess as \"IBCF\" and k=25. k is the number of neighbors to be considered while computing the similarity values as pursues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_evaluate = \"IBCF\"\n",
    "model_parameters = list(k = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accompanying code demonstrates building the recommendation engine model utilizing the \"recommender()\" function and its input parameters such as input data, model to evaluate the parameters, and the k parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recommender of type 'IBCF' for 'realRatingMatrix' \n",
       "learned using 2689 users."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_recommender = Recommender(data = model_data_train, method = model_to_evaluate, parameter = model_parameters)\n",
    "model_recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above model trained and learned to utilize the 2626 training set data. To explore the model we are going to use the \"getModel()\" function which is possible to use in the recommenderlab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 9\n",
      " $ description         : chr \"IBCF: Reduced similarity matrix\"\n",
      " $ sim                 :Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots\n",
      "  .. ..@ i       : int [1:2500] 1 2 9 37 38 72 79 0 18 24 ...\n",
      "  .. ..@ p       : int [1:101] 0 7 20 28 76 83 98 116 137 168 ...\n",
      "  .. ..@ Dim     : int [1:2] 100 100\n",
      "  .. ..@ Dimnames:List of 2\n",
      "  .. .. ..$ : chr [1:100] \"j1\" \"j2\" \"j3\" \"j4\" ...\n",
      "  .. .. ..$ : chr [1:100] \"j1\" \"j2\" \"j3\" \"j4\" ...\n",
      "  .. ..@ x       : num [1:2500] 0.1961 0.1992 0.1319 0.0971 0.119 ...\n",
      "  .. ..@ factors : list()\n",
      " $ k                   : num 25\n",
      " $ method              : chr \"Cosine\"\n",
      " $ normalize           : chr \"center\"\n",
      " $ normalize_sim_matrix: logi FALSE\n",
      " $ alpha               : num 0.5\n",
      " $ na_as_zero          : logi FALSE\n",
      " $ verbose             : logi FALSE\n"
     ]
    }
   ],
   "source": [
    "str(getModel(model_recommender))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above outcomes, the significant parameters to note are k value, the default similitude value, and technique \"cosine similarity. \n",
    "\n",
    "The last advance is to produce the recommendations on the test set. Running the accompanying code on the test set will  create the proposals. \"items_to_recommend\" is the parameter to set the quantity of proposals to be created for every user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recommendations as 'topNList' with n = 20 for 611 users. "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "items_to_recommend = 20\n",
    "model_prediction = predict(object = model_recommender, newdata = model_data_test, n = items_to_recommend)\n",
    "model_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"topNList\"\n",
      "attr(,\"package\")\n",
      "[1] \"recommenderlab\"\n"
     ]
    }
   ],
   "source": [
    "print(class(model_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With slotNames() funciton, we can get the opening subtleties of the forecast article;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'items'</li>\n",
       "\t<li>'ratings'</li>\n",
       "\t<li>'itemLabels'</li>\n",
       "\t<li>'n'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'items'\n",
       "\\item 'ratings'\n",
       "\\item 'itemLabels'\n",
       "\\item 'n'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'items'\n",
       "2. 'ratings'\n",
       "3. 'itemLabels'\n",
       "4. 'n'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"items\"      \"ratings\"    \"itemLabels\" \"n\"         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "slotNames(model_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forecasts produced for the first user in the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/latex": [],
      "text/markdown": [],
      "text/plain": [
       "integer(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_prediction@items[[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the item labels to every foreceasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/latex": [],
      "text/markdown": [],
      "text/plain": [
       "character(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rec_user_1 = model_prediction@items[[1]]\n",
    "joke_user_1 = model_prediction@itemLabels[rec_user_1]\n",
    "joke_user_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluating the Model\n",
    "As we did in UBCF, we can utilize the function evaluationScheme(). Firstly we are going to prepare a test and training sets to obtain the training.\n",
    "\n",
    "The next code will create training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 4  ### n_fold defines the cross-validaton. 3 training sets out of 4 and 1 test set\n",
    "items_to_keep = 20 ### items_to_keep defines the base number of items to use to produce\n",
    "rating_threshold = 3.5 ### rating_threshold defines the minimum raitng that is that is acknowledged as favorable rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>2475</li>\n",
       "\t<li>2475</li>\n",
       "\t<li>2475</li>\n",
       "\t<li>2475</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2475\n",
       "\\item 2475\n",
       "\\item 2475\n",
       "\\item 2475\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2475\n",
       "2. 2475\n",
       "3. 2475\n",
       "4. 2475\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 2475 2475 2475 2475"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_sets = evaluationScheme(data = model_data, method = \"cross-validation\",\n",
    "                            k = n_fold, given = items_to_keep,\n",
    "                            goodRating = rating_threshold)\n",
    "size_sets = sapply(eval_sets@runsTrain, length)\n",
    "size_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the model_to_evaluate to set the recommender method to be utilized. model_parameters characterizes the model parameters, for example, the quantity of neighbors to be considered while processing the closeness utilizing cosine. For the first time being, we are going to set the parameter as NULL so as to make the model pick the default esteems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_evaluate = \"IBCF\"\n",
    "model_parameters = NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With recommender() function will generate the model. To understand the parameters of the recommender() function we will apply the codes as pursues. \n",
    "\n",
    "\"getData\" extracts the training data from eval_sets and passes it on to the recommender() method like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2475 x 100 rating matrix of class 'realRatingMatrix' with 209286 ratings."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getData(eval_sets,\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By reason of we used 4-folds cross-validation, the recommender() function is going to use 3 sets as training set and 1 set as test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_recommender <- Recommender(data = getData(eval_sets, \"train\"), method = model_to_evaluate, parameter = model_parameters)\n",
    "#setting the number of items to be set for recommendations\n",
    "items_to_recommend <- 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did earlier, we will use the predict() function to develop the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'realRatingMatrix'"
      ],
      "text/latex": [
       "'realRatingMatrix'"
      ],
      "text/markdown": [
       "'realRatingMatrix'"
      ],
      "text/plain": [
       "[1] \"realRatingMatrix\"\n",
       "attr(,\"package\")\n",
       "[1] \"recommenderlab\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_prediction = predict(object = eval_recommender, newdata = getData(eval_sets, \"known\"), n = items_to_recommend, \n",
    "                          type = \"ratings\")\n",
    "class(eval_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Accuracy of the Model\n",
    "\n",
    "We will perceive how to assess the model accuracy for the forecasts made on the \"known\" set of test information from eval_sets. We utilize the calcPredictionAccuracy() function to compute the forecast accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_accuracy <- calcPredictionAccuracy(x = eval_prediction, data = getData(eval_sets, \"unknown\"), byUser = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of using byUser = TRUE calculates the accuracy for each user. We are passing the unknown dataset because we are going to calulate the accuracy for the \"known\" set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 6 × 3 of type dbl[,3]</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>RMSE</th><th scope=col>MSE</th><th scope=col>MAE</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>u15547</th><td>4.641288</td><td>21.54156</td><td>3.982811</td></tr>\n",
       "\t<tr><th scope=row>u15994</th><td>5.227975</td><td>27.33172</td><td>4.331063</td></tr>\n",
       "\t<tr><th scope=row>u17322</th><td>5.818398</td><td>33.85376</td><td>4.686194</td></tr>\n",
       "\t<tr><th scope=row>u7299</th><td>4.729074</td><td>22.36414</td><td>3.811318</td></tr>\n",
       "\t<tr><th scope=row>u6662</th><td>6.067747</td><td>36.81755</td><td>5.288377</td></tr>\n",
       "\t<tr><th scope=row>u3970</th><td>6.534409</td><td>42.69850</td><td>5.570576</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 6 × 3 of type dbl{[},3{]}\n",
       "\\begin{tabular}{r|lll}\n",
       "  & RMSE & MSE & MAE\\\\\n",
       "\\hline\n",
       "\tu15547 & 4.641288 & 21.54156 & 3.982811\\\\\n",
       "\tu15994 & 5.227975 & 27.33172 & 4.331063\\\\\n",
       "\tu17322 & 5.818398 & 33.85376 & 4.686194\\\\\n",
       "\tu7299 & 4.729074 & 22.36414 & 3.811318\\\\\n",
       "\tu6662 & 6.067747 & 36.81755 & 5.288377\\\\\n",
       "\tu3970 & 6.534409 & 42.69850 & 5.570576\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 6 × 3 of type dbl[,3]\n",
       "\n",
       "| <!--/--> | RMSE | MSE | MAE |\n",
       "|---|---|---|---|\n",
       "| u15547 | 4.641288 | 21.54156 | 3.982811 |\n",
       "| u15994 | 5.227975 | 27.33172 | 4.331063 |\n",
       "| u17322 | 5.818398 | 33.85376 | 4.686194 |\n",
       "| u7299 | 4.729074 | 22.36414 | 3.811318 |\n",
       "| u6662 | 6.067747 | 36.81755 | 5.288377 |\n",
       "| u3970 | 6.534409 | 42.69850 | 5.570576 |\n",
       "\n"
      ],
      "text/plain": [
       "       RMSE     MSE      MAE     \n",
       "u15547 4.641288 21.54156 3.982811\n",
       "u15994 5.227975 27.33172 4.331063\n",
       "u17322 5.818398 33.85376 4.686194\n",
       "u7299  4.729074 22.36414 3.811318\n",
       "u6662  6.067747 36.81755 5.288377\n",
       "u3970  6.534409 42.69850 5.570576"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(eval_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>RMSE</dt>\n",
       "\t\t<dd>4.85345762257321</dd>\n",
       "\t<dt>MSE</dt>\n",
       "\t\t<dd>25.5084977844772</dd>\n",
       "\t<dt>MAE</dt>\n",
       "\t\t<dd>4.02033406482628</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[RMSE] 4.85345762257321\n",
       "\\item[MSE] 25.5084977844772\n",
       "\\item[MAE] 4.02033406482628\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "RMSE\n",
       ":   4.85345762257321MSE\n",
       ":   25.5084977844772MAE\n",
       ":   4.02033406482628\n",
       "\n"
      ],
      "text/plain": [
       "     RMSE       MSE       MAE \n",
       " 4.853458 25.508498  4.020334 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### The accuracy of the whole model\n",
    "apply(eval_accuracy,2,mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By addressing byUser=FALSE we can compute the model accuracy for the whole model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>RMSE</dt>\n",
       "\t\t<dd>5.05363091194475</dd>\n",
       "\t<dt>MSE</dt>\n",
       "\t\t<dd>25.5391853941635</dd>\n",
       "\t<dt>MAE</dt>\n",
       "\t\t<dd>4.01783924770457</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[RMSE] 5.05363091194475\n",
       "\\item[MSE] 25.5391853941635\n",
       "\\item[MAE] 4.01783924770457\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "RMSE\n",
       ":   5.05363091194475MSE\n",
       ":   25.5391853941635MAE\n",
       ":   4.01783924770457\n",
       "\n"
      ],
      "text/plain": [
       "     RMSE       MSE       MAE \n",
       " 5.053631 25.539185  4.017839 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_accuracy <- calcPredictionAccuracy(x = eval_prediction, data = getData(eval_sets, \"unknown\"), byUser = FALSE)\n",
    "eval_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Accuracy With Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the model accuracy we are going to use ROC curves as we did in the UBCF section. These graphs help us to choose the exchange off between Precision-Recall while picking the parameters we use for the recommender models.\n",
    "\n",
    "The function evaluates () will calculate the similarities using the k-nearest neighbors method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBCF run fold/sample [model time/prediction time]\n",
      "\t 1  [0.2sec/0.2sec] \n",
      "\t 2  [0.19sec/0.17sec] \n",
      "\t 3  [0.17sec/0.15sec] \n",
      "\t 4  [0.17sec/0.15sec] \n"
     ]
    }
   ],
   "source": [
    "result = evaluate(x = eval_sets, method = model_to_evaluate, n = seq(1,100,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1]]\n",
       "An object of class \"confusionMatrix\"\n",
       "Slot \"cm\":\n",
       "          TP        FP           FN          TN precision     recall        TPR\n",
       "1   0.240000  0.760000 22.558787879 56.44121212 0.2400000 0.01088367 0.01088367\n",
       "6   1.538182  4.461818 21.260606061 52.73939394 0.2563636 0.06731554 0.06731554\n",
       "11  2.875152  8.124848 19.923636364 49.07636364 0.2613774 0.12502336 0.12502336\n",
       "16  4.345455 11.654545 18.453333333 45.54666667 0.2715909 0.18731164 0.18731164\n",
       "21  5.861818 15.138182 16.936969697 42.06303030 0.2791342 0.25596949 0.25596949\n",
       "26  7.370909 18.629091 15.427878788 38.57212121 0.2834965 0.32372602 0.32372602\n",
       "31  8.939394 22.060606 13.859393939 35.14060606 0.2883675 0.39382005 0.39382005\n",
       "36 10.538182 25.461818 12.260606061 31.73939394 0.2927273 0.46776368 0.46776368\n",
       "41 12.179394 28.820606 10.619393939 28.38060606 0.2970584 0.54389227 0.54389227\n",
       "46 13.704242 32.295758  9.094545455 24.90545455 0.2979183 0.61164469 0.61164469\n",
       "51 15.223030 35.776970  7.575757576 21.42424242 0.2984908 0.67585871 0.67585871\n",
       "56 16.710303 39.289697  6.088484848 17.91151515 0.2983983 0.74450466 0.74450466\n",
       "61 18.111515 42.888485  4.687272727 14.31272727 0.2969101 0.80204841 0.80204841\n",
       "66 19.476364 46.523636  3.322424242 10.67757576 0.2950964 0.86156832 0.86156832\n",
       "71 20.716364 50.283636  2.082424242  6.91757576 0.2917798 0.91349680 0.91349680\n",
       "76 21.892121 54.107879  0.906666667  3.09333333 0.2880542 0.96178900 0.96178900\n",
       "81 22.793939 57.180606  0.004848485  0.02060606 0.2849912 0.99984595 0.99984595\n",
       "86 22.793939 57.180606  0.004848485  0.02060606 0.2849912 0.99984595 0.99984595\n",
       "91 22.793939 57.180606  0.004848485  0.02060606 0.2849912 0.99984595 0.99984595\n",
       "96 22.793939 57.180606  0.004848485  0.02060606 0.2849912 0.99984595 0.99984595\n",
       "          FPR\n",
       "1  0.01337180\n",
       "6  0.07825295\n",
       "11 0.14241244\n",
       "16 0.20334823\n",
       "21 0.26461643\n",
       "26 0.32556783\n",
       "31 0.38496235\n",
       "36 0.44414997\n",
       "41 0.50207309\n",
       "46 0.56244935\n",
       "51 0.62259730\n",
       "56 0.68392453\n",
       "61 0.74688961\n",
       "66 0.81085095\n",
       "71 0.87705423\n",
       "76 0.94478349\n",
       "81 0.99969608\n",
       "86 0.99969608\n",
       "91 0.99969608\n",
       "96 0.99969608\n",
       "\n",
       "Slot \"model\":\n",
       "NULL\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Accuracy of the model for each fold\n",
    "head(result@results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 20 × 6 of type dbl[,6]</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>TP</th><th scope=col>FP</th><th scope=col>FN</th><th scope=col>TN</th><th scope=col>precision</th><th scope=col>recall</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td> 1.013333</td><td>  2.986667</td><td>90.99393939</td><td>225.0060606</td><td>1.013333</td><td>0.04245248</td></tr>\n",
       "\t<tr><th scope=row>6</th><td> 6.186667</td><td> 17.813333</td><td>85.82060606</td><td>210.1793939</td><td>1.031111</td><td>0.25964962</td></tr>\n",
       "\t<tr><th scope=row>11</th><td>11.781818</td><td> 32.218182</td><td>80.22545455</td><td>195.7745455</td><td>1.071074</td><td>0.49973987</td></tr>\n",
       "\t<tr><th scope=row>16</th><td>17.609697</td><td> 46.390303</td><td>74.39757576</td><td>181.6024242</td><td>1.100606</td><td>0.74760188</td></tr>\n",
       "\t<tr><th scope=row>21</th><td>23.735758</td><td> 60.264242</td><td>68.27151515</td><td>167.7284848</td><td>1.130274</td><td>1.02010788</td></tr>\n",
       "\t<tr><th scope=row>26</th><td>30.015758</td><td> 73.984242</td><td>61.99151515</td><td>154.0084848</td><td>1.154452</td><td>1.30889763</td></tr>\n",
       "\t<tr><th scope=row>31</th><td>36.352727</td><td> 87.647273</td><td>55.65454545</td><td>140.3454545</td><td>1.172669</td><td>1.59709248</td></tr>\n",
       "\t<tr><th scope=row>36</th><td>42.499394</td><td>101.500606</td><td>49.50787879</td><td>126.4921212</td><td>1.180539</td><td>1.87435137</td></tr>\n",
       "\t<tr><th scope=row>41</th><td>48.791515</td><td>115.208485</td><td>43.21575758</td><td>112.7842424</td><td>1.190037</td><td>2.15568913</td></tr>\n",
       "\t<tr><th scope=row>46</th><td>55.012121</td><td>128.987879</td><td>36.99515152</td><td> 99.0048485</td><td>1.195916</td><td>2.43156426</td></tr>\n",
       "\t<tr><th scope=row>51</th><td>61.170909</td><td>142.829091</td><td>30.83636364</td><td> 85.1636364</td><td>1.199430</td><td>2.69774233</td></tr>\n",
       "\t<tr><th scope=row>56</th><td>67.025455</td><td>156.974545</td><td>24.98181818</td><td> 71.0181818</td><td>1.196883</td><td>2.95345052</td></tr>\n",
       "\t<tr><th scope=row>61</th><td>72.738182</td><td>171.261818</td><td>19.26909091</td><td> 56.7309091</td><td>1.192429</td><td>3.19725039</td></tr>\n",
       "\t<tr><th scope=row>66</th><td>78.231515</td><td>185.768485</td><td>13.77575758</td><td> 42.2242424</td><td>1.185326</td><td>3.43427218</td></tr>\n",
       "\t<tr><th scope=row>71</th><td>83.402424</td><td>200.597576</td><td> 8.60484848</td><td> 27.3951515</td><td>1.174682</td><td>3.64723061</td></tr>\n",
       "\t<tr><th scope=row>76</th><td>88.266667</td><td>215.732121</td><td> 3.74060606</td><td> 12.2606061</td><td>1.161411</td><td>3.84748619</td></tr>\n",
       "\t<tr><th scope=row>81</th><td>91.987879</td><td>227.877576</td><td> 0.01939394</td><td>  0.1151515</td><td>1.150247</td><td>3.99918865</td></tr>\n",
       "\t<tr><th scope=row>86</th><td>91.987879</td><td>227.877576</td><td> 0.01939394</td><td>  0.1151515</td><td>1.150247</td><td>3.99918865</td></tr>\n",
       "\t<tr><th scope=row>91</th><td>91.987879</td><td>227.877576</td><td> 0.01939394</td><td>  0.1151515</td><td>1.150247</td><td>3.99918865</td></tr>\n",
       "\t<tr><th scope=row>96</th><td>91.987879</td><td>227.877576</td><td> 0.01939394</td><td>  0.1151515</td><td>1.150247</td><td>3.99918865</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 20 × 6 of type dbl{[},6{]}\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & TP & FP & FN & TN & precision & recall\\\\\n",
       "\\hline\n",
       "\t1 &  1.013333 &   2.986667 & 90.99393939 & 225.0060606 & 1.013333 & 0.04245248\\\\\n",
       "\t6 &  6.186667 &  17.813333 & 85.82060606 & 210.1793939 & 1.031111 & 0.25964962\\\\\n",
       "\t11 & 11.781818 &  32.218182 & 80.22545455 & 195.7745455 & 1.071074 & 0.49973987\\\\\n",
       "\t16 & 17.609697 &  46.390303 & 74.39757576 & 181.6024242 & 1.100606 & 0.74760188\\\\\n",
       "\t21 & 23.735758 &  60.264242 & 68.27151515 & 167.7284848 & 1.130274 & 1.02010788\\\\\n",
       "\t26 & 30.015758 &  73.984242 & 61.99151515 & 154.0084848 & 1.154452 & 1.30889763\\\\\n",
       "\t31 & 36.352727 &  87.647273 & 55.65454545 & 140.3454545 & 1.172669 & 1.59709248\\\\\n",
       "\t36 & 42.499394 & 101.500606 & 49.50787879 & 126.4921212 & 1.180539 & 1.87435137\\\\\n",
       "\t41 & 48.791515 & 115.208485 & 43.21575758 & 112.7842424 & 1.190037 & 2.15568913\\\\\n",
       "\t46 & 55.012121 & 128.987879 & 36.99515152 &  99.0048485 & 1.195916 & 2.43156426\\\\\n",
       "\t51 & 61.170909 & 142.829091 & 30.83636364 &  85.1636364 & 1.199430 & 2.69774233\\\\\n",
       "\t56 & 67.025455 & 156.974545 & 24.98181818 &  71.0181818 & 1.196883 & 2.95345052\\\\\n",
       "\t61 & 72.738182 & 171.261818 & 19.26909091 &  56.7309091 & 1.192429 & 3.19725039\\\\\n",
       "\t66 & 78.231515 & 185.768485 & 13.77575758 &  42.2242424 & 1.185326 & 3.43427218\\\\\n",
       "\t71 & 83.402424 & 200.597576 &  8.60484848 &  27.3951515 & 1.174682 & 3.64723061\\\\\n",
       "\t76 & 88.266667 & 215.732121 &  3.74060606 &  12.2606061 & 1.161411 & 3.84748619\\\\\n",
       "\t81 & 91.987879 & 227.877576 &  0.01939394 &   0.1151515 & 1.150247 & 3.99918865\\\\\n",
       "\t86 & 91.987879 & 227.877576 &  0.01939394 &   0.1151515 & 1.150247 & 3.99918865\\\\\n",
       "\t91 & 91.987879 & 227.877576 &  0.01939394 &   0.1151515 & 1.150247 & 3.99918865\\\\\n",
       "\t96 & 91.987879 & 227.877576 &  0.01939394 &   0.1151515 & 1.150247 & 3.99918865\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 20 × 6 of type dbl[,6]\n",
       "\n",
       "| <!--/--> | TP | FP | FN | TN | precision | recall |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 1 |  1.013333 |   2.986667 | 90.99393939 | 225.0060606 | 1.013333 | 0.04245248 |\n",
       "| 6 |  6.186667 |  17.813333 | 85.82060606 | 210.1793939 | 1.031111 | 0.25964962 |\n",
       "| 11 | 11.781818 |  32.218182 | 80.22545455 | 195.7745455 | 1.071074 | 0.49973987 |\n",
       "| 16 | 17.609697 |  46.390303 | 74.39757576 | 181.6024242 | 1.100606 | 0.74760188 |\n",
       "| 21 | 23.735758 |  60.264242 | 68.27151515 | 167.7284848 | 1.130274 | 1.02010788 |\n",
       "| 26 | 30.015758 |  73.984242 | 61.99151515 | 154.0084848 | 1.154452 | 1.30889763 |\n",
       "| 31 | 36.352727 |  87.647273 | 55.65454545 | 140.3454545 | 1.172669 | 1.59709248 |\n",
       "| 36 | 42.499394 | 101.500606 | 49.50787879 | 126.4921212 | 1.180539 | 1.87435137 |\n",
       "| 41 | 48.791515 | 115.208485 | 43.21575758 | 112.7842424 | 1.190037 | 2.15568913 |\n",
       "| 46 | 55.012121 | 128.987879 | 36.99515152 |  99.0048485 | 1.195916 | 2.43156426 |\n",
       "| 51 | 61.170909 | 142.829091 | 30.83636364 |  85.1636364 | 1.199430 | 2.69774233 |\n",
       "| 56 | 67.025455 | 156.974545 | 24.98181818 |  71.0181818 | 1.196883 | 2.95345052 |\n",
       "| 61 | 72.738182 | 171.261818 | 19.26909091 |  56.7309091 | 1.192429 | 3.19725039 |\n",
       "| 66 | 78.231515 | 185.768485 | 13.77575758 |  42.2242424 | 1.185326 | 3.43427218 |\n",
       "| 71 | 83.402424 | 200.597576 |  8.60484848 |  27.3951515 | 1.174682 | 3.64723061 |\n",
       "| 76 | 88.266667 | 215.732121 |  3.74060606 |  12.2606061 | 1.161411 | 3.84748619 |\n",
       "| 81 | 91.987879 | 227.877576 |  0.01939394 |   0.1151515 | 1.150247 | 3.99918865 |\n",
       "| 86 | 91.987879 | 227.877576 |  0.01939394 |   0.1151515 | 1.150247 | 3.99918865 |\n",
       "| 91 | 91.987879 | 227.877576 |  0.01939394 |   0.1151515 | 1.150247 | 3.99918865 |\n",
       "| 96 | 91.987879 | 227.877576 |  0.01939394 |   0.1151515 | 1.150247 | 3.99918865 |\n",
       "\n"
      ],
      "text/plain": [
       "   TP        FP         FN          TN          precision recall    \n",
       "1   1.013333   2.986667 90.99393939 225.0060606 1.013333  0.04245248\n",
       "6   6.186667  17.813333 85.82060606 210.1793939 1.031111  0.25964962\n",
       "11 11.781818  32.218182 80.22545455 195.7745455 1.071074  0.49973987\n",
       "16 17.609697  46.390303 74.39757576 181.6024242 1.100606  0.74760188\n",
       "21 23.735758  60.264242 68.27151515 167.7284848 1.130274  1.02010788\n",
       "26 30.015758  73.984242 61.99151515 154.0084848 1.154452  1.30889763\n",
       "31 36.352727  87.647273 55.65454545 140.3454545 1.172669  1.59709248\n",
       "36 42.499394 101.500606 49.50787879 126.4921212 1.180539  1.87435137\n",
       "41 48.791515 115.208485 43.21575758 112.7842424 1.190037  2.15568913\n",
       "46 55.012121 128.987879 36.99515152  99.0048485 1.195916  2.43156426\n",
       "51 61.170909 142.829091 30.83636364  85.1636364 1.199430  2.69774233\n",
       "56 67.025455 156.974545 24.98181818  71.0181818 1.196883  2.95345052\n",
       "61 72.738182 171.261818 19.26909091  56.7309091 1.192429  3.19725039\n",
       "66 78.231515 185.768485 13.77575758  42.2242424 1.185326  3.43427218\n",
       "71 83.402424 200.597576  8.60484848  27.3951515 1.174682  3.64723061\n",
       "76 88.266667 215.732121  3.74060606  12.2606061 1.161411  3.84748619\n",
       "81 91.987879 227.877576  0.01939394   0.1151515 1.150247  3.99918865\n",
       "86 91.987879 227.877576  0.01939394   0.1151515 1.150247  3.99918865\n",
       "91 91.987879 227.877576  0.01939394   0.1151515 1.150247  3.99918865\n",
       "96 91.987879 227.877576  0.01939394   0.1151515 1.150247  3.99918865"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns_sum = c(\"TP\",\"FP\",\"FN\",\"TN\",\"precision\",\"recall\") ### to sum all the fold results\n",
    "indices_sum = Reduce(\"+\", getConfusionMatrix(result))[,columns_sum]\n",
    "indices_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAhFBMVEUAAAABAQEFBQUGBgYL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\nQABBAgQQJEAAQQIEECRAAEECBPw/gzQsar0vAUsAAAAASUVORK5CYII=",
      "text/plain": [
       "Plot with title \"ROC Curve\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(result, annotate = TRUE, main = \"ROC Curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAhFBMVEUAAAABAQEFBQUGBgYL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\nQJAAAQQJEECQAAEECRBAkAAB/x/lC5CE7jRHPAAAAABJRU5ErkJggg==",
      "text/plain": [
       "Plot with title \"Precision-Recall\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(result, \"prec/rec\",annotate = TRUE, main =\"Precision-Recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Setting Parameter for Item-based Collaborative Filtering\n",
    "\n",
    "During building the IBCF model, there are some spots that we can select the ideal values before generating the recommendations\n",
    "- We need to pick, the ideal number of neighbors for computing the likenesses between things \n",
    "\n",
    "- Similarity method to be utilized, regardless of whether it is the cosine or Pearson technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'IBCF_cos_k_3'</li>\n",
       "\t<li>'IBCF_cos_k_5'</li>\n",
       "\t<li>'IBCF_cos_k_7'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'IBCF\\_cos\\_k\\_3'\n",
       "\\item 'IBCF\\_cos\\_k\\_5'\n",
       "\\item 'IBCF\\_cos\\_k\\_7'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'IBCF_cos_k_3'\n",
       "2. 'IBCF_cos_k_5'\n",
       "3. 'IBCF_cos_k_7'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"IBCF_cos_k_3\" \"IBCF_cos_k_5\" \"IBCF_cos_k_7\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vector_k = c(3, 5, 7) ### To set different k-values\n",
    "model_1 = lapply(vector_k,function(k,l){list(name = \"IBCF\", param = list(method = \"cosine\", k=k))})\n",
    "names(model_1) = paste0(\"IBCF_cos_k_\",vector_k)\n",
    "names(model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'IBCF_pearson_k_3'</li>\n",
       "\t<li>'IBCF_pearson_k_5'</li>\n",
       "\t<li>'IBCF_pearson_k_7'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'IBCF\\_pearson\\_k\\_3'\n",
       "\\item 'IBCF\\_pearson\\_k\\_5'\n",
       "\\item 'IBCF\\_pearson\\_k\\_7'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'IBCF_pearson_k_3'\n",
       "2. 'IBCF_pearson_k_5'\n",
       "3. 'IBCF_pearson_k_7'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"IBCF_pearson_k_3\" \"IBCF_pearson_k_5\" \"IBCF_pearson_k_7\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_2 = lapply(vector_k, function(k,l){list(name = \"IBCF\",\n",
    "                                   param = \"pearson\", k=k)})\n",
    "names(model_2) = paste0(\"IBCF_pearson_k_\",vector_k)\n",
    "names(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$IBCF_cos_k_3</dt>\n",
       "\t\t<dd><dl>\n",
       "\t<dt>$name</dt>\n",
       "\t\t<dd>'IBCF'</dd>\n",
       "\t<dt>$param</dt>\n",
       "\t\t<dd><dl>\n",
       "\t<dt>$method</dt>\n",
       "\t\t<dd>'cosine'</dd>\n",
       "\t<dt>$k</dt>\n",
       "\t\t<dd>3</dd>\n",
       "</dl>\n",
       "</dd>\n",
       "</dl>\n",
       "</dd>\n",
       "\t<dt>$IBCF_cos_k_5</dt>\n",
       "\t\t<dd><dl>\n",
       "\t<dt>$name</dt>\n",
       "\t\t<dd>'IBCF'</dd>\n",
       "\t<dt>$param</dt>\n",
       "\t\t<dd><dl>\n",
       "\t<dt>$method</dt>\n",
       "\t\t<dd>'cosine'</dd>\n",
       "\t<dt>$k</dt>\n",
       "\t\t<dd>5</dd>\n",
       "</dl>\n",
       "</dd>\n",
       "</dl>\n",
       "</dd>\n",
       "\t<dt>$IBCF_cos_k_7</dt>\n",
       "\t\t<dd><dl>\n",
       "\t<dt>$name</dt>\n",
       "\t\t<dd>'IBCF'</dd>\n",
       "\t<dt>$param</dt>\n",
       "\t\t<dd><dl>\n",
       "\t<dt>$method</dt>\n",
       "\t\t<dd>'cosine'</dd>\n",
       "\t<dt>$k</dt>\n",
       "\t\t<dd>7</dd>\n",
       "</dl>\n",
       "</dd>\n",
       "</dl>\n",
       "</dd>\n",
       "\t<dt>$IBCF_pearson_k_3</dt>\n",
       "\t\t<dd><dl>\n",
       "\t<dt>$name</dt>\n",
       "\t\t<dd>'IBCF'</dd>\n",
       "\t<dt>$param</dt>\n",
       "\t\t<dd>'pearson'</dd>\n",
       "\t<dt>$k</dt>\n",
       "\t\t<dd>3</dd>\n",
       "</dl>\n",
       "</dd>\n",
       "\t<dt>$IBCF_pearson_k_5</dt>\n",
       "\t\t<dd><dl>\n",
       "\t<dt>$name</dt>\n",
       "\t\t<dd>'IBCF'</dd>\n",
       "\t<dt>$param</dt>\n",
       "\t\t<dd>'pearson'</dd>\n",
       "\t<dt>$k</dt>\n",
       "\t\t<dd>5</dd>\n",
       "</dl>\n",
       "</dd>\n",
       "\t<dt>$IBCF_pearson_k_7</dt>\n",
       "\t\t<dd><dl>\n",
       "\t<dt>$name</dt>\n",
       "\t\t<dd>'IBCF'</dd>\n",
       "\t<dt>$param</dt>\n",
       "\t\t<dd>'pearson'</dd>\n",
       "\t<dt>$k</dt>\n",
       "\t\t<dd>7</dd>\n",
       "</dl>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$IBCF\\_cos\\_k\\_3] \\begin{description}\n",
       "\\item[\\$name] 'IBCF'\n",
       "\\item[\\$param] \\begin{description}\n",
       "\\item[\\$method] 'cosine'\n",
       "\\item[\\$k] 3\n",
       "\\end{description}\n",
       "\n",
       "\\end{description}\n",
       "\n",
       "\\item[\\$IBCF\\_cos\\_k\\_5] \\begin{description}\n",
       "\\item[\\$name] 'IBCF'\n",
       "\\item[\\$param] \\begin{description}\n",
       "\\item[\\$method] 'cosine'\n",
       "\\item[\\$k] 5\n",
       "\\end{description}\n",
       "\n",
       "\\end{description}\n",
       "\n",
       "\\item[\\$IBCF\\_cos\\_k\\_7] \\begin{description}\n",
       "\\item[\\$name] 'IBCF'\n",
       "\\item[\\$param] \\begin{description}\n",
       "\\item[\\$method] 'cosine'\n",
       "\\item[\\$k] 7\n",
       "\\end{description}\n",
       "\n",
       "\\end{description}\n",
       "\n",
       "\\item[\\$IBCF\\_pearson\\_k\\_3] \\begin{description}\n",
       "\\item[\\$name] 'IBCF'\n",
       "\\item[\\$param] 'pearson'\n",
       "\\item[\\$k] 3\n",
       "\\end{description}\n",
       "\n",
       "\\item[\\$IBCF\\_pearson\\_k\\_5] \\begin{description}\n",
       "\\item[\\$name] 'IBCF'\n",
       "\\item[\\$param] 'pearson'\n",
       "\\item[\\$k] 5\n",
       "\\end{description}\n",
       "\n",
       "\\item[\\$IBCF\\_pearson\\_k\\_7] \\begin{description}\n",
       "\\item[\\$name] 'IBCF'\n",
       "\\item[\\$param] 'pearson'\n",
       "\\item[\\$k] 7\n",
       "\\end{description}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$IBCF_cos_k_3\n",
       ":   $name\n",
       ":   'IBCF'\n",
       "$param\n",
       ":   $method\n",
       ":   'cosine'\n",
       "$k\n",
       ":   3\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "$IBCF_cos_k_5\n",
       ":   $name\n",
       ":   'IBCF'\n",
       "$param\n",
       ":   $method\n",
       ":   'cosine'\n",
       "$k\n",
       ":   5\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "$IBCF_cos_k_7\n",
       ":   $name\n",
       ":   'IBCF'\n",
       "$param\n",
       ":   $method\n",
       ":   'cosine'\n",
       "$k\n",
       ":   7\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "$IBCF_pearson_k_3\n",
       ":   $name\n",
       ":   'IBCF'\n",
       "$param\n",
       ":   'pearson'\n",
       "$k\n",
       ":   3\n",
       "\n",
       "\n",
       "\n",
       "$IBCF_pearson_k_5\n",
       ":   $name\n",
       ":   'IBCF'\n",
       "$param\n",
       ":   'pearson'\n",
       "$k\n",
       ":   5\n",
       "\n",
       "\n",
       "\n",
       "$IBCF_pearson_k_7\n",
       ":   $name\n",
       ":   'IBCF'\n",
       "$param\n",
       ":   'pearson'\n",
       "$k\n",
       ":   7\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$IBCF_cos_k_3\n",
       "$IBCF_cos_k_3$name\n",
       "[1] \"IBCF\"\n",
       "\n",
       "$IBCF_cos_k_3$param\n",
       "$IBCF_cos_k_3$param$method\n",
       "[1] \"cosine\"\n",
       "\n",
       "$IBCF_cos_k_3$param$k\n",
       "[1] 3\n",
       "\n",
       "\n",
       "\n",
       "$IBCF_cos_k_5\n",
       "$IBCF_cos_k_5$name\n",
       "[1] \"IBCF\"\n",
       "\n",
       "$IBCF_cos_k_5$param\n",
       "$IBCF_cos_k_5$param$method\n",
       "[1] \"cosine\"\n",
       "\n",
       "$IBCF_cos_k_5$param$k\n",
       "[1] 5\n",
       "\n",
       "\n",
       "\n",
       "$IBCF_cos_k_7\n",
       "$IBCF_cos_k_7$name\n",
       "[1] \"IBCF\"\n",
       "\n",
       "$IBCF_cos_k_7$param\n",
       "$IBCF_cos_k_7$param$method\n",
       "[1] \"cosine\"\n",
       "\n",
       "$IBCF_cos_k_7$param$k\n",
       "[1] 7\n",
       "\n",
       "\n",
       "\n",
       "$IBCF_pearson_k_3\n",
       "$IBCF_pearson_k_3$name\n",
       "[1] \"IBCF\"\n",
       "\n",
       "$IBCF_pearson_k_3$param\n",
       "[1] \"pearson\"\n",
       "\n",
       "$IBCF_pearson_k_3$k\n",
       "[1] 3\n",
       "\n",
       "\n",
       "$IBCF_pearson_k_5\n",
       "$IBCF_pearson_k_5$name\n",
       "[1] \"IBCF\"\n",
       "\n",
       "$IBCF_pearson_k_5$param\n",
       "[1] \"pearson\"\n",
       "\n",
       "$IBCF_pearson_k_5$k\n",
       "[1] 5\n",
       "\n",
       "\n",
       "$IBCF_pearson_k_7\n",
       "$IBCF_pearson_k_7$name\n",
       "[1] \"IBCF\"\n",
       "\n",
       "$IBCF_pearson_k_7$param\n",
       "[1] \"pearson\"\n",
       "\n",
       "$IBCF_pearson_k_7$k\n",
       "[1] 7\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Combining all the methods\n",
    "models = append(model_1,model_2)\n",
    "head(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBCF run fold/sample [model time/prediction time]\n",
      "\t 1  [0.17sec/0.16sec] \n",
      "\t 2  [0.19sec/0.13sec] \n",
      "\t 3  [0.17sec/0.14sec] \n",
      "\t 4  [0.19sec/0.14sec] \n",
      "IBCF run fold/sample [model time/prediction time]\n",
      "\t 1  [0.17sec/0.14sec] \n",
      "\t 2  [0.17sec/0.15sec] \n",
      "\t 3  [0.18sec/0.17sec] \n",
      "\t 4  [0.17sec/0.16sec] \n",
      "IBCF run fold/sample [model time/prediction time]\n",
      "\t 1  [0.17sec/0.17sec] \n",
      "\t 2  [0.17sec/0.15sec] \n",
      "\t 3  [0.17sec/0.18sec] \n",
      "\t 4  [0.17sec/0.16sec] \n",
      "IBCF run fold/sample [model time/prediction time]\n",
      "\t 1  [0.18sec/0.17sec] \n",
      "\t 2  [0.17sec/0.16sec] \n",
      "\t 3  [0.16sec/0.14sec] \n",
      "\t 4  [0.17sec/0.16sec] \n",
      "IBCF run fold/sample [model time/prediction time]\n",
      "\t 1  [0.15sec/0.19sec] \n",
      "\t 2  [0.19sec/0.16sec] \n",
      "\t 3  [0.18sec/0.19sec] \n",
      "\t 4  [0.17sec/0.17sec] \n",
      "IBCF run fold/sample [model time/prediction time]\n",
      "\t 1  [0.16sec/0.19sec] \n",
      "\t 2  [0.18sec/0.16sec] \n",
      "\t 3  [0.17sec/0.19sec] \n",
      "\t 4  [0.2sec/0.17sec] \n"
     ]
    }
   ],
   "source": [
    "### The total number of recommendations\n",
    "number_recommendations = c(1,5, seq(1,100,15))\n",
    "### Building 4-Fold methods\n",
    "list_results = evaluate(x = eval_sets, method = models, n = number_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List of evaluation results for 6 recommenders:\n",
       "Evaluation results for 4 folds/samples using method 'IBCF'.\n",
       "Evaluation results for 4 folds/samples using method 'IBCF'.\n",
       "Evaluation results for 4 folds/samples using method 'IBCF'.\n",
       "Evaluation results for 4 folds/samples using method 'IBCF'.\n",
       "Evaluation results for 4 folds/samples using method 'IBCF'.\n",
       "Evaluation results for 4 folds/samples using method 'IBCF'."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the results will help to choose best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAA2FBMVEUAAAAAAP8APgAAUwAA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\nIBKABRAJwAKIBGABRAKwACIBWOD/AyLXd+xpz1lqAAAAAElFTkSuQmCC",
      "text/plain": [
       "Plot with title \"ROC Curve\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(list_results, annotate = c(1,5), legend = \"topleft\")\n",
    "title(\"ROC Curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAqFBMVEUAAAAAAP8APgAAtQAA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\nYII=",
      "text/plain": [
       "Plot with title \"Precision-Recall\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(list_results, \"prec/rec\", annotate =c(1,5), legend = \"right\")\n",
    "title(\"Precision-Recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Analysis of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the preceding ROC plot, we can say that all neighborhoods of Pearson methods have exactly the same behavior. With AUC (Area under the curve) we can easily see that the best methods for IBFC with cosine similarity are with vector_k = 7. Even though cosine vector_k = 7 gives the best model, any Pearson method can be used as a good approach to build an acceptable model. With using the ROC curves, our goal is to understand data and take actions to reduce the FPR rate. In our case reducing <b>False Negative</b> rate is important which is 171.261818 at 61<sup>th</sup> recommendation from confusion matrix which we found 2 sections before.\n",
    "\n",
    "On the other hand, when we analyze the precision-recall plot 61<sup>th</sup> recommendation seems to have the best accuracy. To understand this plot we need to look at the false negative and false positive rates. Precision is fed by false positive rates and recall fed by false negative rates. The best spot for this curve is like the maximum point of a curve which has derivative 0. In this plot again Pearson methods behave the same way and their maximum point is 61 again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Refences\n",
    "\n",
    "1. Sharma, Richa & Singh, Rahul. (2016). Evolution of Recommender Systems from Ancient Times to Modern Era: A Survey. Indian Journal of Science and Technology. 9. 10.17485/ijst/2016/v9i20/88005.\n",
    "2. Sharma, Richa & Singh, Rahul. (2016). op. cit.\n",
    "3. Gorakala, S, K. (2016) Building Recommendation Engines. Birmingham, UK: Packt Publishing Ltd.\n",
    "4. Gorakala, S, K. (2016). op. cit.\n",
    "5. Gorakala, S, K. (2016). op. cit.\n",
    "6. Gorakala, S, K. (2016). op. cit.\n",
    "7. Press, W. H.; Flannery, B. P.; Teukolsky, S. A.; and Vetterling, W. T. (1992). \"Singular Value Decomposition.\" §2.6 in Numerical Recipes in FORTRAN: The Art of Scientific Computing, 2nd ed. Cambridge, England: Cambridge University Press.\n",
    "8. Golub, G. H. and Van Loan, C. F. (1996) Matrix Computations. Baltimore, Maryland: The Johns Hopkins University Press. \n",
    "9. Ken Goldberg, Theresa Roeder, Dhruv Gupta, and Chris Perkins. \"Eigentaste: A Constant Time Collaborative Filtering Algorithm.\" Information Retrieval, 4(2), 133-151. July 2001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
